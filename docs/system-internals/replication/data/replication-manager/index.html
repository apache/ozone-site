<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-system-internals/replication/data/replication-manager" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">SCM Replication Manager | Apache Ozone</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ozone.apache.org/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://ozone.apache.org/img/social-card.png"><meta data-rh="true" property="og:url" content="https://ozone.apache.org/docs/system-internals/replication/data/replication-manager"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="SCM Replication Manager | Apache Ozone"><meta data-rh="true" name="description" content="The Replication Manager (RM) is a critical thread which runs inside the leader SCM daemon in an Ozone cluster. Its role is to periodically check the health of each container in the cluster, and take action for any containers which are not optimally replicated. Often that action involves arranging for new replicas of the container to be created, but it can also involve closing the replicas, deleting empty replicas, and so on."><meta data-rh="true" property="og:description" content="The Replication Manager (RM) is a critical thread which runs inside the leader SCM daemon in an Ozone cluster. Its role is to periodically check the health of each container in the cluster, and take action for any containers which are not optimally replicated. Often that action involves arranging for new replicas of the container to be created, but it can also involve closing the replicas, deleting empty replicas, and so on."><link data-rh="true" rel="canonical" href="https://ozone.apache.org/docs/system-internals/replication/data/replication-manager"><link data-rh="true" rel="alternate" href="https://ozone.apache.org/docs/system-internals/replication/data/replication-manager" hreflang="en"><link data-rh="true" rel="alternate" href="https://ozone.apache.org/docs/system-internals/replication/data/replication-manager" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YQWKI4BIJ7-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Ozone RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Ozone Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Apache Ozone" href="/opensearch.xml">
<link rel="manifest" href="/pwa/manifest.json">

<link rel="icon" href="favicon.ico" sizes="32x32">
<link rel="icon" href="favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="apple-touch-icon.png">
<meta name="google-site-verification" content="fXhAWQ_Jb1fOk6QlN9a7Zs_Xsj-E2U0Q8oFqTNVclaE">
<meta name="algolia-site-verification" content="A2998EF969F36A0D">
<script src="/script/matomo.js"></script><link rel="stylesheet" href="/assets/css/styles.27c88cdc.css">
<script src="/assets/js/runtime~main.dc044eab.js" defer="defer"></script>
<script src="/assets/js/main.6c1c0e49.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_wi3M" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/ozone-logo.svg" alt="Ozone Logo" class="themedComponent_Ka_G themedComponent--light_hIiB"><img src="/img/ozone-logo.svg" alt="Ozone Logo" class="themedComponent_Ka_G themedComponent--dark_GbLg"></div><b class="navbar__title text--truncate">Apache Ozone</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs">Docs</a><a class="navbar__item navbar__link" href="/download">Download</a><a class="navbar__item navbar__link" href="/roadmap">Roadmap</a><a class="navbar__item navbar__link" href="/faq">FAQ</a><a class="navbar__item navbar__link" href="/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/community/communication-channels">Communication Channels</a></li><li><a class="dropdown__link" href="/community/who-uses-ozone">Who Uses Ozone?</a></li><li><a class="dropdown__link" href="/community/report-an-issue">Report An Issue</a></li><li><a class="dropdown__link" href="/community/ask-a-question">Ask a Question</a></li><li><a class="dropdown__link" href="/community/how-to-contribute">How to Contribute</a></li><li><a class="dropdown__link" href="/community/events-and-media">Events and Media</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_NU7Q"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/docs/system-internals/replication/data/replication-manager" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><a href="https://github.com/apache/ozone" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub Repo"></a><div class="toggle_F0tt colorModeToggle_Cksm"><button class="clean-btn toggleButton_tFD4 toggleButtonDisabled_UmGx" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_gzz6"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_HsWo"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_SQAi"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_HMzJ"><div class="docsWrapper_TA0s"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton__Euq" type="button"></button><div class="docRoot_VN1Z"><aside class="theme-doc-sidebar-container docSidebarContainer_jdpB"><div class="sidebarViewport_pKkV"><div class="scrollCustom_InGK"><div class="customSidebarVersion_kZiw"><div class="customSidebarInner_rBmt"><span style="display:inline-block">Version:</span> <a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/system-internals/replication/data/replication-manager">Next</a></div></div><div id="sidebarCssSelector_uq97"><div class="sidebar_W81o"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_KB1A"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/quick-start/">Quick Start</a><button aria-label="Expand sidebar category &#x27;Quick Start&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/core-concepts/">Core Concepts</a><button aria-label="Expand sidebar category &#x27;Core Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/user-guide/">User Guide</a><button aria-label="Expand sidebar category &#x27;User Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/administrator-guide/">Administrator Guide</a><button aria-label="Expand sidebar category &#x27;Administrator Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/troubleshooting/">Troubleshooting</a><button aria-label="Expand sidebar category &#x27;Troubleshooting&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/system-internals/">System Internals</a><button aria-label="Collapse sidebar category &#x27;System Internals&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/components/">Components</a><button aria-label="Expand sidebar category &#x27;Components&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/data-operations/">Data Operations</a><button aria-label="Expand sidebar category &#x27;Data Operations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/data-integrity/">Data Integrity</a><button aria-label="Expand sidebar category &#x27;Data Integrity&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/system-internals/replication/">Replication</a><button aria-label="Collapse sidebar category &#x27;Replication&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/system-internals/replication/metadata">Metadata</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/system-internals/replication/data/">Data</a><button aria-label="Collapse sidebar category &#x27;Data&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/replication/data/write-pipelines/">Write Pipelines</a><button aria-label="Expand sidebar category &#x27;Write Pipelines&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/replication/data/containers/">Containers</a><button aria-label="Expand sidebar category &#x27;Containers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/system-internals/replication/data/replication-manager">SCM Replication Manager</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/system-internals/replication/data/container-balancer">SCM Container Balancer</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/security/">Security</a><button aria-label="Expand sidebar category &#x27;Security&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/network-protocols/">Network Protocols</a><button aria-label="Expand sidebar category &#x27;Network Protocols&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/system-internals/features/">Features</a><button aria-label="Expand sidebar category &#x27;Features&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/developer-guide/">Developer Guide</a><button aria-label="Expand sidebar category &#x27;Developer Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></div></div></aside><main class="docMainContainer_YnIx"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_oKcN"><div class="docItemContainer_EnqJ"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_JwNh" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_gcoS"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/system-internals/"><span itemprop="name">System Internals</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/system-internals/replication/"><span itemprop="name">Replication</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/system-internals/replication/data/"><span itemprop="name">Data</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">SCM Replication Manager</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_my_n theme-doc-toc-mobile tocMobile_mwTw"><button type="button" class="clean-btn tocCollapsibleButton_v3oV">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>SCM Replication Manager</h1></header>
<p>The Replication Manager (RM) is a critical thread which runs inside the leader SCM daemon in an Ozone cluster. Its role is to periodically check the health of each container in the cluster, and take action for any containers which are not optimally replicated. Often that action involves arranging for new replicas of the container to be created, but it can also involve closing the replicas, deleting empty replicas, and so on.</p>
<h2 class="anchor anchorWithStickyNavbar_e_9H" id="architecture">Architecture<a href="#architecture" class="hash-link" aria-label="Direct link to Architecture" title="Direct link to Architecture">​</a></h2>
<p>The RM process is split into stages - one to check containers and identify those that need action and another to process the actionable containers.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="container-check-stage">Container Check Stage<a href="#container-check-stage" class="hash-link" aria-label="Direct link to Container Check Stage" title="Direct link to Container Check Stage">​</a></h3>
<p>The check phase runs periodically at 5 minute intervals. First it gathers a list of all containers on the cluster, and each container is passed through a chain of rules to identify if it has any issues. These rules are arranged in a similar way to the “Chain of Responsibility” design pattern, where the first rule which “matches” causes the chain to exit. Each type of check is implemented in a standalone Java class, and the checks are processed in a defined order:</p>
<div class="language-java codeBlockContainer_mZR4 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_rIoO"><pre tabindex="0" class="prism-code language-java codeBlock_kDDR thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_SQL2"><span class="token-line" style="color:#393A34"><span class="token plain">containerCheckChain = new OpenContainerHandler(this);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">containerCheckChain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new ClosingContainerHandler(this, clock))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new QuasiClosedContainerHandler(this))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new MismatchedReplicasHandler(this))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new EmptyContainerHandler(this))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new DeletingContainerHandler(this))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(ecReplicationCheckHandler)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(ratisReplicationCheckHandler)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new ClosedWithUnhealthyReplicasHandler(this))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(ecMisReplicationCheckHandler)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new RatisUnhealthyReplicationCheckHandler())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .addNext(new VulnerableUnhealthyReplicasHandler(this));</span><br></span></code></pre><div class="buttonGroup_QU8l"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_PE_v" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_bUEh"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_DKrM"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_e_9H" id="replicationmanager-report">ReplicationManager Report<a href="#replicationmanager-report" class="hash-link" aria-label="Direct link to ReplicationManager Report" title="Direct link to ReplicationManager Report">​</a></h2>
<p>Each time the check phase of the Replication Manager runs, it generates a report which can be accessed via the command <em>container report</em> command. This command is described in the administrator guide under <a href="/docs/administrator-guide/operations/container-replication-report">Replication Manager Report</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="container-state-descriptions">Container State Descriptions<a href="#container-state-descriptions" class="hash-link" aria-label="Direct link to Container State Descriptions" title="Direct link to Container State Descriptions">​</a></h3>
<p>The first section of the report “Container State Summary” summarizes the state of all containers in the cluster. Containers can move through these states as they are opened, filled with block data and have data removed over time. A container should only be in one of these states at any time, and the sum of the containers in this section should equal the number of containers in the cluster.</p>
<p><img decoding="async" loading="lazy" alt="Container States Visualized" src="/assets/images/container-states-visualized-45bba17930c54023c2a2a2e7ab188c40.png" width="2816" height="1536" class="img_zmyy"></p>
<p>Each state is explored in the following sections.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="open">Open<a href="#open" class="hash-link" aria-label="Direct link to Open" title="Direct link to Open">​</a></h4>
<p>Open containers are available for writes into the cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="closing">Closing<a href="#closing" class="hash-link" aria-label="Direct link to Closing" title="Direct link to Closing">​</a></h4>
<p>Closing containers are in the process of being closed. They will transition to closing when they have enough data to be considered full, or there is an issue with the write pipeline, such as a Datanode going down.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="quasi-closed">Quasi-Closed<a href="#quasi-closed" class="hash-link" aria-label="Direct link to Quasi-Closed" title="Direct link to Quasi-Closed">​</a></h4>
<p>A container moves to quasi-closed when a Datanode attempts to close the replica, but it was not able to close it cleanly due to the Ratis Pipeline being unavailable. This could happen if a Datanode goes down unexpectedly, for example. Replication Manager will attempt to close the container by identifying the replica with the highest Block Commit Sequence ID (BCSID) and close it. As replicas with older BCSID are stale, new copies will be made from the closed replica before removing the stale replicas.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="closed">Closed<a href="#closed" class="hash-link" aria-label="Direct link to Closed" title="Direct link to Closed">​</a></h4>
<p>Closed containers have successfully transitioned from closing to closed. This is a normal state for containers to move to, and the majority of containers in the cluster should be in this state.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="deleting">Deleting<a href="#deleting" class="hash-link" aria-label="Direct link to Deleting" title="Direct link to Deleting">​</a></h4>
<p>Containers which were closed and had all blocks deleted over time leaving them empty transition to deleting. The containers remain in this state until all the replicas have been removed from the Datanodes.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="deleted">Deleted<a href="#deleted" class="hash-link" aria-label="Direct link to Deleted" title="Direct link to Deleted">​</a></h4>
<p>When the “deleting” process completes and all replicas have been removed, the container will move to the deleted state and remain there.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="recovering">Recovering<a href="#recovering" class="hash-link" aria-label="Direct link to Recovering" title="Direct link to Recovering">​</a></h4>
<p>Recovering is a temporary state container replicas can go into on the Datanodes, and is related to EC reconstruction. The report should always have a count of zero for this state, as the state is not managed by the Replication Manager.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="container-health-summary">Container Health Summary<a href="#container-health-summary" class="hash-link" aria-label="Direct link to Container Health Summary" title="Direct link to Container Health Summary">​</a></h3>
<p>The next section of the report lists the number of containers in various health states on the cluster. Note that a count of “healthy” containers is not presented, only degraded states.  In an otherwise healthy cluster, the Replication Manager should work to correct the state of any containers in the states listed, except for Missing and Unhealthy which it cannot repair.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="under-replicated">Under Replicated<a href="#under-replicated" class="hash-link" aria-label="Direct link to Under Replicated" title="Direct link to Under Replicated">​</a></h4>
<p>Under-Replicated containers have less than the number of expected replicas. This could be caused by decommissioning or maintenance mode transitions on the Datanode, or due to failed disks or failed nodes within the cluster. Unhealthy replicas also make a container under-replicated, as they have an issue which must be corrected. See the Unhealthy section below for more details on the unhealthy state. The Replication Manager will schedule commands to make additional copies of the under replicated containers.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="mis-replicated">Mis-Replicated<a href="#mis-replicated" class="hash-link" aria-label="Direct link to Mis-Replicated" title="Direct link to Mis-Replicated">​</a></h4>
<p>If the container has the correct number of replicas, but they are not spread across sufficient racks to meet the requirements of the container placement policy, the container is Mis-Replicated. Again, Replication Manager will work to move replicas to additional racks by making new copies of the relevant replicas and then removing the excess.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="over-replicated">Over Replicated<a href="#over-replicated" class="hash-link" aria-label="Direct link to Over Replicated" title="Direct link to Over Replicated">​</a></h4>
<p>Over Replicated containers have too many replicas. This could occur due to correcting mis-replication, or if a decommissioned or down host is returned to the cluster after the under replication has been corrected. Replication Manager will schedule delete replica commands to remove the excess replicas while maintaining the container placement policy rules around rack placement.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="missing">Missing<a href="#missing" class="hash-link" aria-label="Direct link to Missing" title="Direct link to Missing">​</a></h4>
<p>A container is missing if there are not enough replicas available to read it. For a Ratis container, that would mean zero copies are online. For an EC container, it is marked as missing if less than “data number” of replicas are available. Eg, for a RS-6-3 container, having less than 6 replicas online would render it missing. For missing containers, the Replication Manager cannot do anything to correct them. Manual intervention will be needed to bring lost nodes back into the cluster, or take steps to remove the containers from SCM and any related keys from OM, as the data will not be accessible.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="unhealthy">Unhealthy<a href="#unhealthy" class="hash-link" aria-label="Direct link to Unhealthy" title="Direct link to Unhealthy">​</a></h4>
<p>A container is unhealthy, if it is not missing and there are insufficient healthy replicas to allow the container to be read completely.</p>
<p>A replica can get marked as unhealthy by the scanner process on the Datanode for various reasons. For example, it can detect if a block in the container has an invalid checksum and mark the replica unhealthy. For a Ratis container, it will be marked as unhealthy if all its container replicas are unhealthy with no healthy replicas available. Note that it may be possible to read most of the data in an unhealthy container. For Ratis, each replica could have a different issue affecting a different block in each replica, for example a checksum violation on read. The Ozone client would catch the read error and try the read again from another replica. However data recovery will depend on the number and level of corruption, and whether the same blocks are corrupted in all replicas.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="unhealthy-ratis">Unhealthy Ratis<a href="#unhealthy-ratis" class="hash-link" aria-label="Direct link to Unhealthy Ratis" title="Direct link to Unhealthy Ratis">​</a></h4>
<p>A Ratis container with 3 replicas, Healthy, Healthy, Unhealthy is still fully readable and hence recoverable, so it will be marked as under replicated as the unhealthy replica needs to be replaced. A Ratis container with 3 Unhealthy replicas will be marked as unhealthy. It is not missing, as there are replicas available and it is not under-replicated as it has all 3 copies. A Ratis container with only 2 unhealthy replicas is both unhealthy and under replicated, and it will be marked as both Unhealthy and Under-Replicated. The Replication Manager will attempt to make an additional copy of the unhealthy container to resolve the under replication, but it will not be able to correct the unhealthy state without manual intervention, as there is no good copy to copy from.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="unhealthy-ec">Unhealthy EC<a href="#unhealthy-ec" class="hash-link" aria-label="Direct link to Unhealthy EC" title="Direct link to Unhealthy EC">​</a></h4>
<p>EC containers are similar. They are only marked unhealthy if they are not missing (at least data number of replicas available), but there isn’t at least “data number” of healthy replicas. See the following tables for examples:</p>
<table><thead><tr><th>Index = 1</th><th>Index = 2</th><th>Index = 3</th><th>Index = 4</th><th>Index = 5</th><th>State</th></tr></thead><tbody><tr><td>Healthy</td><td>Healthy</td><td>Healthy</td><td>Unhealthy</td><td>Unhealthy</td><td>Under-Rep</td></tr><tr><td>Healthy</td><td>Healthy</td><td>Healthy</td><td></td><td></td><td>Under-Rep</td></tr><tr><td>Healthy</td><td>Healthy</td><td>Unhealthy</td><td></td><td></td><td>Unhealthy</td></tr><tr><td>Healthy</td><td>Healthy</td><td></td><td></td><td></td><td>Missing</td></tr><tr><td>Healthy</td><td>Healthy + Unhealthy</td><td></td><td></td><td></td><td>Missing and Over Replicated</td></tr><tr><td>Healthy</td><td>Healthy + Unhealthy</td><td>Healthy</td><td></td><td></td><td>Under and Over Replicated</td></tr></tbody></table>
<p>Note it is possible for an EC container to be both Unhealthy and Over Replicated, as there may be two copies of the same index, one healthy and one unhealthy.</p>
<p>If a container is unhealthy, the Replication Manager will not be able to correct it without some manual intervention, as unhealthy replicas cannot be used in reconstruction. It may be possible to read much of the data from the container as an unhealthy container may only have an issue with a single block, but if there are legitimate corruptions in an unhealthy EC container it is likely at least some of the data is unreadable.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="empty">Empty<a href="#empty" class="hash-link" aria-label="Direct link to Empty" title="Direct link to Empty">​</a></h4>
<p>A container is marked as empty if it has been closed and then all data blocks stored in the container have been removed. When this is detected, the container transitions from CLOSED to DELETING and therefore containers should only stay in the Empty state until the next Replication Manager check stage.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="open-unhealthy">Open Unhealthy<a href="#open-unhealthy" class="hash-link" aria-label="Direct link to Open Unhealthy" title="Direct link to Open Unhealthy">​</a></h4>
<p>When a container is open, it is expected that all the replicas are also in the same open state. If an issue occurs, which causes a replica to move from the open state, the Replication Manager will mark the container as Open Unhealthy and trigger the close process. Normally such a container will have transitioned to Closing or Closed by the next Replication Manager check stage.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="quasi-closed-stuck">Quasi-Closed Stuck<a href="#quasi-closed-stuck" class="hash-link" aria-label="Direct link to Quasi-Closed Stuck" title="Direct link to Quasi-Closed Stuck">​</a></h4>
<p>This is relevant only for Ratis containers. When a container is in the quasi-closed state, the Replication Manager needs to wait for the majority of replicas (2 out of 3) to reach the quasi-closed state before it can transition the container to closed. While this is not the case, the container will be marked as quasi-closed Stuck.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="unhealthy-container-samples">Unhealthy Container Samples<a href="#unhealthy-container-samples" class="hash-link" aria-label="Direct link to Unhealthy Container Samples" title="Direct link to Unhealthy Container Samples">​</a></h4>
<p>To facilitate investigating issues with degraded containers, the report includes a sample of the first 100 container IDs in each state and includes them in the report. Given these IDs, it is possible to see if the same containers are continuously stuck, and also get more information about the container via the “ozone admin container info ID” command.</p>
<h2 class="anchor anchorWithStickyNavbar_e_9H" id="replication-task-throttling">Replication Task Throttling<a href="#replication-task-throttling" class="hash-link" aria-label="Direct link to Replication Task Throttling" title="Direct link to Replication Task Throttling">​</a></h2>
<p>To protect the cluster from being overloaded with replication tasks, it is important that a limited number of replication tasks run on the cluster at any time. The load on Datanodes can change over time and this will impact their speed at processing the tasks. In addition to throttling concurrent work, it is important the replication coordinator (SCM) does not queue too many tasks on Datanodes. If tasks are queued on a slow Datanode, then SCM cannot reschedule the task elsewhere until it times out. It is preferable to schedule the work on the Datanodes in smaller increments, with a goal of giving the Datanode enough work to keep it busy for a heartbeat duration.</p>
<p>Datanodes are given replication tasks in the response to their periodic heartbeat. Included in the heartbeat from the Datanode, is a report detailing the number of each type of command currently queued on the Datanode. Any commands queued on SCM in the “Datanode Command Queue” are sent to the Datanode in the heartbeat response, and the Datanode command count is stored in the SCM NodeManager. The command count stored in Node Manager is the sum of the count reported by the Datanode and the number of commands sent in the heartbeat response.</p>
<p>Replication Manager can use the stored command counts to limit the number of commands queued on a Datanode.</p>
<p>Replication Manager schedules 3 types of commands which must be throttled:</p>
<ol>
<li>Replicate Container Commands - Used to correct Ratis under replication, both Ratis and EC mis-replication and to make extra copies of a container during decommission and maintenance for both Ratis and EC containers.</li>
<li>Delete Container Replica Commands - Used to resolve over replication and also to delete containers in unexpected states.</li>
<li>EC Reconstruction - These are the most expensive commands which are used to recover lost EC replicas.</li>
</ol>
<p>The following sections will explore the throttling use for each of the major command types.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="replicate-container-commands">Replicate Container Commands<a href="#replicate-container-commands" class="hash-link" aria-label="Direct link to Replicate Container Commands" title="Direct link to Replicate Container Commands">​</a></h3>
<p>In the Legacy Replication Manager, a replicate container command was sent to the node which will receive the new target, and the command would contain a list of available sources it can download from. When the under replicated containers were concentrated on a few source nodes, this resulted in commands running on lots of targets attempting to download from a limited number of sources at the same time, overloading them.</p>
<p>Now, the commands are sent to the source node and instructed to send the command to the new target. Normally, the target nodes are quite random, but in the case of decommission, and especially with EC containers on a decommissioning node, the sources can be concentrated on only a single or few nodes, so this tends to work better.</p>
<p>To balance and throttle the load of Replicate Commands on each Datanode, replication manager uses the current command count stored in Node Manager. Any source nodes which have too many commands scheduled are filtered out and those that remain are sorted based on the number of commands queued. The command is sent to the Datanode with the least commands queued.</p>
<p>If all sources have too many commands queued, the container cannot be replicated, and the command is requeued to be tried again later.</p>
<p>Note there are two types of replication commands - simple replication and EC Reconstruction. On the Datanode they share the same Datanode queue and worker thread pool, so it makes sense to have a single combined limit. As EC Reconstruction commands are more expensive to process than replication commands, they are given a weighting so that queuing one command counts 1 * weight to the limit. The default weight is currently 3.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="the-balancer-and-low-priority-commands">The Balancer and Low Priority Commands<a href="#the-balancer-and-low-priority-commands" class="hash-link" aria-label="Direct link to The Balancer and Low Priority Commands" title="Direct link to The Balancer and Low Priority Commands">​</a></h4>
<p>The Balancer process also sends replicate commands via the Replication Manager API to even out the space used on nodes across the cluster. The Balancer works using the concept of an iteration. It assesses the state of the cluster and decides which nodes are over and under utilized. Then it schedules a large number of move commands to move data from the overused nodes to underused nodes. These commands are scheduled on the Datanodes, initially as Replicate Container Commands, and as they complete as Delete Container Replica commands.</p>
<p>This can create a large number of commands on the Datanode queues and may also impact the more important replication of containers if some nodes go offline. To combat this, the Replicate Container Commands can be sent with two priorities - Normal and Low. The Balancer always sends Low priority Replicate Container commands, while Replication Manager always sends Normal priority commands. Low priority commands do not count toward the queue size reported in the Datanode heartbeat. If the Datanode has Normal priority commands queued, the Low priority commands will not be processed. That way, if there is a large amount of Balancer work scheduled, and some essential replication work is required, it will get priority.</p>
<p>The Balancer also schedules commands with a larger timeout, to give time for the large iteration of work to complete and also to cater for any higher priority commands which may slow its progress.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="delete-container-replica-commands">Delete Container Replica Commands<a href="#delete-container-replica-commands" class="hash-link" aria-label="Direct link to Delete Container Replica Commands" title="Direct link to Delete Container Replica Commands">​</a></h3>
<p>Deleting a container is a less resource intensive operation than replicating a container, but as a container can have many small block files, it can still take a bit of time to run on a Datanode, and therefore should be throttled.</p>
<p>Depending on container placement, type and the placement policy, to resolve an over-replicated container a Delete Container Replica command may need to be sent to a specific Datanode or it could be sent to any node hosting a copy of the replica. For example, with EC, an over replicated container would indicate at least 2 copies of at least one replica index. In this case, the delete command could be sent to either replica, but container placement may restrict that to a single replica.</p>
<p>The delete container commands are throttled in much the same way as for Replicate Container Commands. When a delete command is attempted, the current command count is checked and if the Datanode is overloaded, another replica is tried or the container will be requeued and attempted again later.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="the-balancer-and-delete-commands">The Balancer and Delete Commands<a href="#the-balancer-and-delete-commands" class="hash-link" aria-label="Direct link to The Balancer and Delete Commands" title="Direct link to The Balancer and Delete Commands">​</a></h4>
<p>Unlike with Replication commands, there is no priority ordering for delete container replica commands, for several reasons:</p>
<ol>
<li>Delete is less important than replication, as a delayed delete cannot result in data loss.</li>
<li>The balancer delete commands are triggered by the completion of a replicate command and this rate of completion naturally throttles the delete.</li>
<li>Delete commands are less resource intensive, and hence the Datanode should be able to deal with a large number quickly.</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="ec-reconstruction-commands">EC Reconstruction Commands<a href="#ec-reconstruction-commands" class="hash-link" aria-label="Direct link to EC Reconstruction Commands" title="Direct link to EC Reconstruction Commands">​</a></h3>
<p>EC Reconstruction commands are the most expensive commands scheduled on Datanodes. A reconstruction command will recover between 1 and EC scheme parity number replicas and read from EC scheme data number replicas.</p>
<p>For an EC 6-3 container, 6 Datanodes will be used as sources to read data from, while between 1 and 3 target Datanodes will receive the recovered data. One of the target Datanodes will also act as the coordinator and read from the sources, perform the EC reconstruction calculation and write the recovered data to a new local container and also to remote containers if there are multiple replicas being recovered.</p>
<p>The coordinator node will receive the command and the total number of commands queued on a Datanode can be throttled in the same way as before, using the command count queue in Node Manager. With replication commands, the command must be sent to an existing source, so the nodes which can receive the command are limited. With EC Reconstruction, the command is sent to a target, and the target is selected somewhat randomly from the spare nodes on the cluster.</p>
<p>For this reason it makes sense to track the nodes which have reached their command limit, and avoid selecting them as a target. This is achieved by updating an exclude list in the replication manager when the last schedule command reached the limit for that node. There is a callback which tells the replication manager the Datanode has heartbeat via replicationManager.DatanodeCommandCountUpdate() to remove nodes from the exclude list. At this time the exclude list is only used when selecting targets for reconstruction commands, not for replication commands.</p>
<p>EC Reconstruction commands share the same limits on the Datanodes as replication commands, but reconstruction commands are given a weighting (default 3 at the current time) as they are more expensive for the coordinator node to run.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="limitations-of-ec-reconstruction-throttling">Limitations of EC Reconstruction Throttling<a href="#limitations-of-ec-reconstruction-throttling" class="hash-link" aria-label="Direct link to Limitations of EC Reconstruction Throttling" title="Direct link to Limitations of EC Reconstruction Throttling">​</a></h4>
<p>For EC Reconstruction, there are many other nodes involved in a reconstruction command. The command coordinator will need to read from several sources and write to itself and possibly other nodes if more than one replica is being reconstructed. Limiting the number of commands queued on a given node may not provide sufficient throttling if many nodes are attempting EC reconstruction simultaneously.</p>
<p>For replication, the entire container must be tarred and sent in a single stream to a new target. EC will read a container block by block, more like a client reading from the cluster, therefore the read load it places on hosts is likely to be less intensive and spread over a longer period than replication, allowing more requests to be interleaved without performance issues.</p>
<p>EC container groups should also be larger than Ratis containers. The combined data size in a group can be up to 10 times larger than a Ratis container (EC-10-4), so there are likely to be fewer EC containers in a cluster for a given data size than Ratis, resulting in fewer reconstruction commands being required.</p>
<p>At the current time, the plan is to continue with the simple throttling as described above and monitor how well it works in practice. There will also be a global replication limit, as described before to limit the total number of inflight operations.</p>
<h4 class="anchor anchorWithStickyNavbar_e_9H" id="ec-and-decommissioning">EC and Decommissioning<a href="#ec-and-decommissioning" class="hash-link" aria-label="Direct link to EC and Decommissioning" title="Direct link to EC and Decommissioning">​</a></h4>
<p>When a node hosting a Ratis container is decommissioned, there are generally 3 sources available for the container replicas. One on the decommissioning host, and then 2 others on somewhat random nodes across the cluster. This allows the decommissioning load and hence speed of decommission to be shared across many more nodes.</p>
<p>For an EC container, the decommissioning host is likely the only source of the replica which needs to be copied and hence the decommission will be slower.</p>
<p>A host which is decommissioning is generally not used for Ratis reads unless there are no other nodes available, but it would still be used for EC reads to avoid online reconstruction. As decommission progresses on the node, and new copies are formed, the read load will decline over time. Furthermore, decommissioning nodes are not used for writes, so they should be under less load than other cluster nodes.</p>
<p>Due to the reduced load on a decommissioning host, it is possible to increase the number of commands queued on a decommissioning host and also increase the size of the executor thread pool to process the commands.</p>
<p>When a Datanode switches to a decommissioning state, it will adjust the size of the replication supervisor thread pool higher, and if the node returns to the In Service state, it will return to the lower thread pool limit.</p>
<p>Similarly when scheduling commands, SCM can allocate more commands to the decommissioning host, as it should process them more quickly due to the lower load and increased thread pool.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="global-replication-command-limit">Global Replication Command Limit<a href="#global-replication-command-limit" class="hash-link" aria-label="Direct link to Global Replication Command Limit" title="Direct link to Global Replication Command Limit">​</a></h3>
<p>As well as the above Datanode limits, it is possible to configure a global replication limit, limiting the number of inflight containers pending creation. A larger cluster would be capable of having more inflight replication than a smaller cluster, so the limit should be a function of the number of Datanodes on the cluster, and the limit of the number of commands which can be queued per Datanode and some weighting factor.</p>
<p>For example, if each Datanode can queue 20 replication commands, and there are 100 nodes in the cluster, then the natural limit is 20 * 100. However, that assumes that commands are queued evenly across all Datanodes, which is unlikely. With a global limit we would prefer that all Datanodes are not fully loaded with replication commands simultaneously, so we may want to impose a limit of half that number, with a factor of 0.5, eg 20 * 100 * 0.5 = 1k pending replications.</p>
<p>At one extreme this would result in all Datanodes in the cluster having half their maximum tasks queued, but in practice, some DNs are likely to be at their limit while others have zero or less than half queued.</p>
<p>If the limits were perfectly defined, such that in a single heartbeat a Datanode can complete all its queued work just at the end of the heartbeat interval, then reducing the number of queued commands by half would make the Datanode busy for only half its heartbeat interval. As the Datanodes will all heartbeat at different times, all the busy and non-work periods across all the Datanodes would combine in a load profile that would show some Datanodes are always idle, reducing the overall load on the cluster.</p>
<p>Datanodes have a queue limit, but they process the queue with a thread pool (default 10). So even if they have a queue of 20,10 would be running concurrently. Furthermore, if the queue is filled with EC Reconstruction commands, with weighting factor of 3, then the limit is ceil(20 / 3) which is 7, reducing the commands running in parallel when they are more expensive. Another way to reduce or increase the replication load in the cluster is by adjusting the Datanode replication thread pool size. Ideally, the Datanode thread pool is sized to a level that allows the Datanode to replicate “thread pool” number of tasks simultaneously with little impact on client workloads. While network bandwidth can become a limiting factor, the number of disks is more likely to be the first bottleneck, and therefore the thread pool size should ideally be based on the number of disks on the node.</p>
<p>Rather than using command counts to set the global limit, the ContainerReplicaPendingOps table inside SCM can be used. It keeps a running count of the number of replicas pending creation on the cluster, and is updated in a close to real time way via the Incremental Container Reports from SCM. It also handles EC Reconstruction commands that may create several replicas as it keeps a record of each container being added, so we can count the real number of containers being added, rather than just the command count.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="global-delete-limit">Global Delete Limit<a href="#global-delete-limit" class="hash-link" aria-label="Direct link to Global Delete Limit" title="Direct link to Global Delete Limit">​</a></h3>
<p>Container replica deletes tend to be targeted to a single node, and the Datanode already has a thread pool to handle them, which limits the number running concurrently. There is also no network impact when deleting a container. Therefore, there is no global command limit for delete commands.</p>
<h2 class="anchor anchorWithStickyNavbar_e_9H" id="relevant-configuration-parameters">Relevant Configuration Parameters<a href="#relevant-configuration-parameters" class="hash-link" aria-label="Direct link to Relevant Configuration Parameters" title="Direct link to Relevant Configuration Parameters">​</a></h2>
<p>Defaults are given in brackets after the parameter.</p>
<ul>
<li><code>hdds.scm.replication.datanode.replication.limit</code> - (20) Total number of replication commands that can be queued on a Datanode. The limit is made up of number_of_replication_commands + reconstruction_weight * number_of_reconstruction_commands</li>
<li><code>hdds.scm.replication.datanode.reconstruction.weight</code> - (3) The weight to apply to multiple reconstruction commands before adding to the Datanode.replication.limit.</li>
<li><code>hdds.scm.replication.datanode.delete.container.limit</code> - (40) The total number of delete container commands to queue on a given Datanode.</li>
<li><code>hdds.scm.replication.inflight.limit.factor</code> - (0.75) The overall replication task limit on a cluster is the number of healthy nodes, times the Datanode.replication.limit. This factor, which should be between zero and 1, scales that limit down to reduce the overall number of replicas pending creation on the cluster. A setting of zero disables global limit checking. A setting of 1 effectively disables it, by making the limit equal to the above equation. However if there are many decommissioning nodes on the cluster, the decommission nodes will have a higher than normal limit, so the setting of 1 may still provide some limit in extreme circumstances.</li>
<li><code>hdds.datanode.replication.outofservice.limit.factor</code> - (2.0) When a Datanode is decommissioning its replication thread pool (<code>hdds.datanode.replication.streams.limit (10)</code>) is multiplied by this factor to allocate more threads for replication . On SCM, the limit for any Datanode which is not IN_SERVICE (ie decommission or maintenance) is also increased by the same factor. This allows the node to dedicate more resources to replication as it will not be used to writes and will be reduced in priority for reads.</li>
<li><code>hdds.scm.replication.event.timeout</code> - (300 seconds) The amount of time SCM allows for a task scheduled on a Datanode to complete. After this duration, the Datanode will discard the command and SCM will assume it has been lost and schedule another if still relevant.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_e_9H" id="future-ideas">Future Ideas<a href="#future-ideas" class="hash-link" aria-label="Direct link to Future Ideas" title="Direct link to Future Ideas">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="limiting-ops-per-node">Limiting Ops per node<a href="#limiting-ops-per-node" class="hash-link" aria-label="Direct link to Limiting Ops per node" title="Direct link to Limiting Ops per node">​</a></h3>
<p>For EC Reconstruction, there are so many other nodes involved in a reconstruction command it may not be sufficient to throttle only on the target node. The targets are likely to be quite random across the cluster, and if every node on the cluster got a few reconstruction commands, it would possibly overload the cluster as it tries to perform all the operations on the other nodes.</p>
<p>For replication commands, if the sources are quite random, and for some reason there are only a few target nodes, it is not good if all the sources are replicating to the same target.</p>
<p>For these two reasons, should we attempt to limit the number of commands referencing nodes other than the command targets? Eg a replication command is sent to a single source and it copies a container to a target. We could count 1 toward the target node and perhaps count 1 toward the source. An EC Reconstruction would reference EC Data number sources and up to EC parity number targets. We could count 1 against each of those nodes.</p>
<p>If the count against a given node is beyond some threshold, then that node should be excluded as a target, or being used as an EC source.</p>
<p>The under replication handler thread currently runs in a loop, and it processes its queue until the queue is empty and then sleeps. Any failed tasks are held in a list and added back to the queue after the iteration completes.</p>
<p>We could keep this list of “used nodes” for an iteration and then reset it. It would not be perfect, but the goal is to have the Datanodes complete their work in a heartbeat or two. If we have the sleep interval set at 2 x heartbeat interval, then it may work quite well.</p>
<p>It is not simple to have a persisted set of node usage counts, as we don’t get any feedback on when commands complete.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="dynamically-adjusting-the-datanode-replication-thread-pool">Dynamically Adjusting the Datanode Replication Thread Pool<a href="#dynamically-adjusting-the-datanode-replication-thread-pool" class="hash-link" aria-label="Direct link to Dynamically Adjusting the Datanode Replication Thread Pool" title="Direct link to Dynamically Adjusting the Datanode Replication Thread Pool">​</a></h3>
<p>In theory it would be possible for SCM to send commands to a Datanode to tell it to adjust its thread pool size to scale up or down the number of simultaneous replication tasks which can run. If SCM noted a lot of under replication on the cluster, it could decide to increase the Datanode thread pool size to give priority to the cluster repairing under replication rather than client workloads.</p>
<h3 class="anchor anchorWithStickyNavbar_e_9H" id="datanode-replication-thread-pool-based-on-number-of-disks">Datanode Replication Thread Pool based on number of disks<a href="#datanode-replication-thread-pool-based-on-number-of-disks" class="hash-link" aria-label="Direct link to Datanode Replication Thread Pool based on number of disks" title="Direct link to Datanode Replication Thread Pool based on number of disks">​</a></h3>
<p>A Datanode with more disks should be able to handle more replication tasks simultaneously than a Datanode with few disks. It is also possible to have mixed sized nodes in a cluster, and Datanodes with a large number of disks would ideally have a different replication thread pool size than nodes with fewer disks. As it stands, the replication thread pool size is a static value, but it could be make into a simple function on the number of disks, eg 2 * number of disks, with a max value.</p>
<p>Similarly, on SCM it would be able to queue more commands on these larger nodes and ideally SCM queue limits would be adjusted higher for larger nodes, and also take that into consideration in any global limit for replication tasks. At the moment, I believe SCM is not aware of the disk count on a Datanode, but if that information was included in the heartbeat, then SCM could have a queue limit based on the disk count (and replication thread pool size).</p>
<p>Alternatively, the Datanode could include the replication thread pool size in the heartbeat, and then SCM could impose the replication limit based on that.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/apache/ozone-site/tree/master/docs/07-system-internals/04-replication/02-data/03-replication-manager.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_kQtw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_orCj"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/system-internals/replication/data/containers/offline-reconstruction"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Reconstruction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/system-internals/replication/data/container-balancer"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">SCM Container Balancer</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_reur thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#architecture" class="table-of-contents__link toc-highlight">Architecture</a><ul><li><a href="#container-check-stage" class="table-of-contents__link toc-highlight">Container Check Stage</a></li></ul></li><li><a href="#replicationmanager-report" class="table-of-contents__link toc-highlight">ReplicationManager Report</a><ul><li><a href="#container-state-descriptions" class="table-of-contents__link toc-highlight">Container State Descriptions</a></li><li><a href="#container-health-summary" class="table-of-contents__link toc-highlight">Container Health Summary</a></li></ul></li><li><a href="#replication-task-throttling" class="table-of-contents__link toc-highlight">Replication Task Throttling</a><ul><li><a href="#replicate-container-commands" class="table-of-contents__link toc-highlight">Replicate Container Commands</a></li><li><a href="#delete-container-replica-commands" class="table-of-contents__link toc-highlight">Delete Container Replica Commands</a></li><li><a href="#ec-reconstruction-commands" class="table-of-contents__link toc-highlight">EC Reconstruction Commands</a></li><li><a href="#global-replication-command-limit" class="table-of-contents__link toc-highlight">Global Replication Command Limit</a></li><li><a href="#global-delete-limit" class="table-of-contents__link toc-highlight">Global Delete Limit</a></li></ul></li><li><a href="#relevant-configuration-parameters" class="table-of-contents__link toc-highlight">Relevant Configuration Parameters</a></li><li><a href="#future-ideas" class="table-of-contents__link toc-highlight">Future Ideas</a><ul><li><a href="#limiting-ops-per-node" class="table-of-contents__link toc-highlight">Limiting Ops per node</a></li><li><a href="#dynamically-adjusting-the-datanode-replication-thread-pool" class="table-of-contents__link toc-highlight">Dynamically Adjusting the Datanode Replication Thread Pool</a></li><li><a href="#datanode-replication-thread-pool-based-on-number-of-disks" class="table-of-contents__link toc-highlight">Datanode Replication Thread Pool based on number of disks</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Apache Software Foundation</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Foundation<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="footer__link-item">License<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="footer__link-item">Events<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sponsorship<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://privacy.apache.org/policies/privacy-policy-public.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Security<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Thanks<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/ozone/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/github.svg" alt="GitHub Discussions Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://issues.apache.org/jira/projects/HDDS/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/jira.svg" alt="Jira Issues Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">Jira Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://infra.apache.org/slack.html" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/slack.svg" alt="Slack Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="mailto:dev@ozone.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/mail.svg" alt="Mailing List Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">Mailing List<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@ApacheOzone" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/youtube.svg" alt="YouTube Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/ApacheOzone" target="_blank" rel="noopener noreferrer" class="footer__link-item"><img src="/img/social/twitter-x.svg" alt="Twitter Icon" style="width:1em;height:1em;margin-right:0.5em;vertical-align:middle">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QWNa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Repositories</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/ozone" target="_blank" rel="noopener noreferrer" class="footer__link-item">Ozone</a></li><li class="footer__item"><a href="https://github.com/apache/ozone-site" target="_blank" rel="noopener noreferrer" class="footer__link-item">Website</a></li><li class="footer__item"><a href="https://github.com/apache/ozone-docker" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docker Image</a></li><li class="footer__item"><a href="https://github.com/apache/ozone-docker-runner" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docker Runner Image</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">
        <div>
          Copyright © 2026 <a href="https://www.apache.org/" class="copyright-link">The Apache Software Foundation</a>. Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0" class="copyright-link">Apache License, Version 2.0</a>. <br>
          <div>
            <p>The Apache Software Foundation, Apache Ozone, Ozone, Apache, the Apache Feather, and the Apache Ozone project logo are either registered trademarks or trademarks of the Apache Software Foundation.</p>
          </div>
        </div></div></div></div></footer></div>
</body>
</html>