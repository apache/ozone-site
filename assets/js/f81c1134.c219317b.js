"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2026/01/30/apache-ozone-best-practices-at-didi","metadata":{"permalink":"/blog/2026/01/30/apache-ozone-best-practices-at-didi","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2026-01-30-apache-ozone-best-practices-at-didi.md","source":"@site/blog/2026-01-30-apache-ozone-best-practices-at-didi.md","title":"Apache Ozone Best Practices at Didi: Scaling to Tens of Billions of Files","description":"Guest post by the Didi Engineering Team. For the full story with detailed slides, see Apache Ozone Best Practices at Didi (PDF).","date":"2026-01-30T00:00:00.000Z","tags":[{"inline":true,"label":"user-stories","permalink":"/blog/tags/user-stories"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"erasure-coding","permalink":"/blog/tags/erasure-coding"},{"inline":true,"label":"scale","permalink":"/blog/tags/scale"}],"readingTime":4.49,"hasTruncateMarker":true,"authors":[{"name":"Kaun-Hung (Rich) Huang","title":"Apache Ozone Contributor","url":"https://github.com/rich7420","imageURL":"https://github.com/rich7420.png","key":"rich7420","page":null},{"name":"Wei-Chiu Chuang","title":"Apache Ozone PMC","url":"https://github.com/jojochuang","imageURL":"https://github.com/jojochuang.png","key":"jojochuang","page":null},{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null}],"frontMatter":{"title":"Apache Ozone Best Practices at Didi: Scaling to Tens of Billions of Files","date":"2026-01-30T00:00:00.000Z","authors":["rich7420","jojochuang","apache-ozone-community"],"tags":["user-stories","performance","erasure-coding","scale"]},"unlisted":false,"nextItem":{"title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","permalink":"/blog/2026/01/29/disk-balancer-preview"}},"content":"Guest post by the Didi Engineering Team. For the full story with detailed slides, see [Apache Ozone Best Practices at Didi (PDF)](https://ozone.apache.org/assets/ApacheOzoneBestPracticesAtDidi.pdf).\\n\\nAs Didi\'s volume of unstructured data surged into the hundreds of petabytes, comprising tens of billions of files, their traditional storage architecture faced severe scalability bottlenecks. This post summarizes how they migrated from HDFS to Apache Ozone, the optimizations they implemented for high-performance reads, and their journey in contributing these improvements back to the community.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Challenge: HDFS at Scale\\n\\nLike many data-driven enterprises, Didi relied heavily on HDFS. However, as their data scale grew, they hit the classic \\"NameNode Limit.\\"\\n\\n- **Metadata Pressure:** Storing hundreds of millions of files put immense pressure on the HDFS NameNode memory.\\n- **Block Reporting Storms:** With massive file counts, block reporting became a significant overhead.\\n- **Scalability Ceiling:** They needed a solution that could handle tens of billions of files without partitioning their clusters into unmanageable silos.\\n\\n## Why Ozone?\\n\\nThey chose Apache Ozone as their next-generation storage engine because it addresses these limitations architecturally:\\n\\n- **Decoupled Metadata:** By separating the Ozone Manager (OM) for namespace and Storage Container Manager (SCM) for block management, Ozone scales significantly better than HDFS.\\n- **RocksDB-based Metadata:** Unlike HDFS, which relies entirely on heap memory, Ozone stores metadata in RocksDB, removing the memory bottleneck.\\n- **Container Logic:** Managing data in \\"containers\\" rather than individual blocks reduces the reporting overhead on the SCM.\\n\\nToday, Ozone has been running in production at Didi for over two years, managing hundreds of PB of storage.\\n\\n![Figure 1: Ozone Cluster Scale at Didi](/img/blog/ozone-cluster-scale-at-didi.png)\\n\\n## Architecture & Key Optimizations\\n\\nMigrating was just the first step. To meet Didi\'s strict latency requirements (especially for \\"first-frame\\" read access), they engineered several critical optimizations.\\n\\n### 1. Multi-Cluster Routing with ViewFs\\n\\nTo manage the sheer volume of data, they utilized a client-side routing mechanism inspired by HDFS ViewFs. By mapping paths to specific clusters (e.g., `vol/bucket/prefix1` \u2192 cluster1), they effectively balanced the load and kept the file count in each cluster under 5 billion, alleviating RPC pressure on individual Ozone Managers.\\n\\n### 2. Boosting Read Performance: S3G Follower Reads\\n\\nThey observed that the Leader OM often became a bottleneck for S3 Gateway (S3G) requests. To solve this, they implemented a Follower Read strategy.\\n\\nThey introduced a \\"probe task\\" in the client (e.g. every 3 seconds) that evaluates:\\n\\n- **Latency:** Selects the OM node with the lowest response time.\\n- **Freshness:** Checks the lastAppliedIndex to ensure the Follower isn\'t serving stale data.\\n\\n**Result:** The P90 latency for S3G metadata requests (GetMetaLatency) dropped from a weekly average of ~90ms to ~17ms; in best cases, from tens of milliseconds to under 3ms.\\n\\n![Figure 6-2. S3G Download Latency Monitoring After FollowerRead Goes Online](/img/blog/s3g-download-latency-follower-read-goes-online.png)\\n\\n### 3. Heterogeneous Caching (HDD + NVMe)\\n\\nDidi\'s clusters use cost-effective hard disk drives, but random reads on small files (tens of MBs) suffered from disk latency. They designed a heterogeneous caching layer:\\n\\n- **Strategy:** They cache the first Chunk (1MB) of each block on high-speed NVMe SSDs; for EC (e.g. RS-6-3-1024k) they cache the first stripe (9MB: 6 data + 3 parity) to cover first-frame needs.\\n- **Impact:** The 6MB of actual data in that stripe is sufficient for most first-frame requests, dramatically improving read speeds without the cost of all-flash storage.\\n- **Implementation:** A custom LRU cache on the Datanode manages this hot data, ensuring efficient space utilization. This caching optimization brought at least 100ms latency improvement in first-frame reads.\\n\\n### 4. Concurrency & Lock Optimization\\n\\nDuring high-concurrency testing, they identified thread contention issues. Specifically, a spin lock in `ChunkUtils#processFileExclusive` was causing CPU spikes.\\n\\nThey contributed a fix (see [HDDS-11281](https://issues.apache.org/jira/browse/HDDS-11281)) that replaced the global lock with a `Striped<ReadWriteLock>`. This granular locking mechanism reduced lock contention and improved system throughput, yielding a performance gain of at least 50ms per operation in contended scenarios.\\n\\n## Cost Efficiency: Erasure Coding (EC)\\n\\nWith data growing at >1PB per day, the 3-replica cost model was unsustainable. They transitioned to Erasure Coding (EC) using the RS-6-3-1024k policy.\\n\\n- **Storage Savings:** Reduced replication factor from 3x to ~1.5x, saving 50% on hardware.\\n- **Challenges Solved:** They encountered and fixed issues with deletion backlogs ([HDDS-11498](https://issues.apache.org/jira/browse/HDDS-11498)), insufficient EC pipelines ([HDDS-11209](https://issues.apache.org/jira/browse/HDDS-11209)), and Safe Mode logic for EC containers ([HDDS-11243](https://issues.apache.org/jira/browse/HDDS-11243)), ensuring EC is as robust as replication in production.\\n\\n## Community Contributions\\n\\nDidi\'s journey with Ozone has been deeply collaborative. We are proud to highlight that Didi\'s contributors have brought several key fixes and improvements back to the Apache Ozone community:\\n\\n- [HDDS-11483](https://issues.apache.org/jira/browse/HDDS-11483): Increased S3G buffer size (e.g. to 4MB) to reduce network I/O and improve first-frame latency.\\n- [HDDS-11209](https://issues.apache.org/jira/browse/HDDS-11209): Avoid insufficient EC pipelines in the container pipeline cache (OM must not cache EC pipelines with incomplete Datanodes).\\n- [HDDS-9342](https://issues.apache.org/jira/browse/HDDS-9342): Fixed OM HA crash and restart failure caused by timing inconsistency between applyTransactionMap and double-buffer.\\n- [HDDS-10985](https://issues.apache.org/jira/browse/HDDS-10985): EC Reconstruction failed because the size of currentChunks was not equal to checksumBlockDataChunks.\\n\\n## Summary & Future Work\\n\\nApache Ozone has successfully enabled Didi to scale its storage infrastructure to hundreds of petabytes while maintaining high performance and lowering costs.\\n\\nLooking ahead, Didi is exploring:\\n\\n- **IO_URING:** To further enhance asynchronous I/O efficiency.\\n- **SPDK:** To accelerate access to RocksDB on NVMe drives for OM and SCM.\\n\\nDidi thanks the Apache Ozone community for their support and vibrant collaboration. The transition to Ozone has been a game-changer for Didi\'s big data infrastructure."},{"id":"/2026/01/29/disk-balancer-preview","metadata":{"permalink":"/blog/2026/01/29/disk-balancer-preview","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2026-01-29-disk-balancer-preview.md","source":"@site/blog/2026-01-29-disk-balancer-preview.md","title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","description":"Ever replaced a drive on a Datanode only to watch it become an I/O hotspot?","date":"2026-01-29T00:00:00.000Z","tags":[{"inline":true,"label":"Ozone","permalink":"/blog/tags/ozone"},{"inline":true,"label":"Disk Balancer","permalink":"/blog/tags/disk-balancer"},{"inline":true,"label":"Ozone 2.2","permalink":"/blog/tags/ozone-2-2"},{"inline":true,"label":"Datanode","permalink":"/blog/tags/datanode"}],"readingTime":4.835,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null},{"name":"Wei-Chiu Chuang","title":"Apache Ozone PMC","url":"https://github.com/jojochuang","imageURL":"https://github.com/jojochuang.png","key":"jojochuang","page":null},{"name":"Yu-Chen Lai","title":"Apache Ozone Contributor","url":"https://github.com/0lai0","imageURL":"https://github.com/0lai0.png","key":"0lai0","page":null},{"name":"Gargi Jaiswal","title":"Apache Ozone Contributor","url":"https://github.com/Gargi-jais11","imageURL":"https://github.com/Gargi-jais11.png","key":"Gargi-jais11","page":null}],"frontMatter":{"title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","authors":["apache-ozone-community","jojochuang","0lai0","Gargi-jais11"],"date":"2026-01-29T00:00:00.000Z","tags":["Ozone","Disk Balancer","Ozone 2.2","Datanode"]},"unlisted":false,"prevItem":{"title":"Apache Ozone Best Practices at Didi: Scaling to Tens of Billions of Files","permalink":"/blog/2026/01/30/apache-ozone-best-practices-at-didi"},"nextItem":{"title":"Accessing Ozone S3 via CyberDuck","permalink":"/blog/2025/07/02/access-ozone-via-cyberduck"}},"content":"Ever replaced a drive on a Datanode only to watch it become an I/O hotspot?\\nOr seen one disk hit 95% usage while others on the same machine sit idle?\\nThese imbalances create performance bottlenecks and increase failure risk.\\nApache Ozone\'s new intra-node Disk Balancer is designed to fix this\u2014automatically.\\n\\n\x3c!-- truncate --\x3e\\n\\nCluster-wide balancing in Ozone already ensures replicas are evenly spread across Datanodes. But inside a single Datanode, disks can still drift out of balance over time \u2014 for example after adding new disks, replacing hardware, or performing large deletions. This leads to I/O hotspots and uneven wear.\\n\\nDisk Balancer closes that gap.\\n\\n## Why Disk Balancer?\\n\\n- **Disks fill unevenly** when nodes gain or lose volumes.\\n\\n- **Large deletes** can empty some disks disproportionately.\\n\\n- **Hot disks degrade performance** and become failure risks.\\n\\nEven if the cluster is balanced, the node itself may not be. Disk Balancer fixes this automatically.\\n\\n## How it works\\n\\nThe design ([HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)) introduces a simple metric: **Volume Data Density** \u2014 how much a disk\'s utilization deviates from the node\'s average. If the deviation exceeds a threshold, the node begins balancing.\\n\\nBalancing is local and safe:\\n\\n- Only **closed containers** are moved.\\n- Moves happen entirely **within the same Datanode.**\\n- A scheduler periodically checks for imbalance and dispatches copy-and-import tasks.\\n- Bandwidth and concurrency are **operator-tunable** to avoid interfering with production I/O.\\n\\nThis runs independently on each Datanode. To use it, first enable the feature by setting `hdds.datanode.disk.balancer.enabled = true` in `ozone-site.xml` on your Datanodes. Once enabled, clients use `ozone admin datanode diskbalancer` commands to talk directly to Datanodes, with SCM only used to discover IN_SERVICE Datanodes when running batch operations with `--in-service-datanodes`.\\n\\n## How DiskBalancer Decides What to Move\\n\\nDiskBalancer uses simple but robust policies to decide **which disks to balance** and **which containers to move** (see the design doc for details: `diskbalancer.md` in [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)).\\n\\n- **Default Volume Choosing Policy**: Picks the most over\u2011utilized volume as the source and the most under\u2011utilized volume as the destination, based on each disk\u2019s **Volume Data Density** and the Datanode\u2019s average utilization.\\n- **Default Container Choosing Policy**: Scans containers on the source volume and moves only **CLOSED** containers that are not already being moved. To avoid repeatedly scanning the same list, it caches container metadata with automatic expiry.\\n\\nThese defaults aim to make safe, incremental moves that converge the disks toward an even utilization state.\\n\\n### Container Move Process\\n\\nWhen DiskBalancer moves a container from one disk to another on the **same Datanode**, it follows a careful **\\"Copy-Validate-Replace\\"** flow (summarized from the design doc for [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)):\\n\\n1. Create a temporary copy of the CLOSED container on the destination disk.\\n2. Transition that copy into a **RECOVERING** state and import it as a new container on the destination.\\n3. Once import and metadata updates succeed, delete the original CLOSED container from the source disk.\\n\\nThis ensures that data is always consistent: the destination copy is fully validated before the original is removed, minimizing risk during balancing.\\n\\n## Using Disk Balancer\\n\\nFirst, enable the Disk Balancer feature on each Datanode by setting the following in `ozone-site.xml`:\\n\\n- `hdds.datanode.disk.balancer.enabled = true`\\n\\nThe Disk Balancer CLI supports two command patterns:\\n\\n- `ozone admin datanode diskbalancer <command> --in-service-datanodes` - Operate on all **IN_SERVICE and HEALTHY** Datanodes\\n- `ozone admin datanode diskbalancer <command> <dn-hostname/dn-ipaddress:port>` - Operate on a specific Datanode\\n\\nAvailable commands:\\n\\n- **start** - Start the Disk Balancer on the target Datanode(s)\\n- **stop** - Stop the Disk Balancer on the target Datanode(s)\\n- **status** - Check the current Disk Balancer status\\n- **report** - Get a volume density report showing imbalance across disks\\n- **update** - Update Disk Balancer configuration settings\\n\\nExamples:\\n\\n```bash\\n# Start Disk Balancer\\nozone admin datanode diskbalancer start --in-service-datanodes\\nor\\nozone admin datanode diskbalancer start ozone-datanode-1 ozone-datanode-5\\n\\n# user can also specifiy configuration parameters during start\\nozone admin datanode diskbalancer start -t <value> -b <value> -p <value> -s <value> --in-service-datanodes\\nor\\nozone admin datanode diskbalancer start -t <value> -b <value> -p <value> -s <value> ozone-datanode-1\\n\\n# Stop Disk Balancer\\nozone admin datanode diskbalancer stop --in-service-datanodes\\nor\\nozone admin datanode diskbalancer stop 192.168.1.100:9860\\n\\n# Check status\\nozone admin datanode diskbalancer status --in-service-datanodes\\nor\\nozone admin datanode diskbalancer status ozone-datanode-1\\n\\n# Get volume density report\\nozone admin datanode diskbalancer report --in-service-datanodes\\nor\\nozone admin datanode diskbalancer report 192.168.1.100:9860\\n\\n# Update configuration\\nozone admin datanode diskbalancer update -t <value> -b <value> -p <value> -s <value> --in-service-datanodes\\nor\\nozone admin datanode diskbalancer update -t <value> -b <value> -p <value> -s <value> ozone-datanode-1\\n```\\n\\n### Configuration Parameters\\n\\nThe following parameters can be specified during **start** or **update configuration** Disk Balancer:\\n\\n| Parameter | Short Flag | Default Value | Description |\\n| --------- | ---------- |---------------| ----------- |\\n| `--threshold` | `-t` | `10.0`        | Percentage deviation from average utilization of the disks after which a Datanode will be rebalanced. |\\n| `--bandwidth-in-mb` | `-b` | `10`          | Maximum bandwidth for DiskBalancer per second. |\\n| `--parallel-thread` | `-p` | `5`           | Max parallel thread count for DiskBalancer. |\\n| `--stop-after-disk-even` | `-s` | `true`        | Stop DiskBalancer automatically after disk utilization is even. |\\n\\n## Benefits for operators\\n\\n- **Even I/O load** across disks \u2192 more stable performance.\\n- **Smooth ops after hardware changes** (new or replaced disks).\\n- **Hands-off balancing** once enabled.\\n- **Clear metrics** for observability and troubleshooting.\\n\\nIt complements the existing Container Balancer: one works across nodes, the other within nodes.\\n\\n## Closing Thoughts\\n\\nDisk Balancer is small but impactful. It brings Ozone closer to being a fully self-healing, self-balancing object store \u2014 reducing hotspots, simplifying maintenance, and improving cluster longevity.\\n\\nOzone 2.2 will ship with this feature available via simple CLI controls and safe defaults. If you run long-lived clusters, this is a feature to watch.\\n\\nFor more information, check out [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)."},{"id":"/2025/07/02/access-ozone-via-cyberduck","metadata":{"permalink":"/blog/2025/07/02/access-ozone-via-cyberduck","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2025-07-02-access-ozone-via-cyberduck.md","source":"@site/blog/2025-07-02-access-ozone-via-cyberduck.md","title":"Accessing Ozone S3 via CyberDuck","description":"Here\'s a step\u2011by\u2011step guide to mounting and managing your Apache Ozone object store\'s S3 interface using CyberDuck.","date":"2025-07-02T00:00:00.000Z","tags":[{"inline":true,"label":"Ozone","permalink":"/blog/tags/ozone"},{"inline":true,"label":"S3","permalink":"/blog/tags/s-3"},{"inline":true,"label":"CyberDuck","permalink":"/blog/tags/cyber-duck"}],"readingTime":3.095,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null}],"frontMatter":{"title":"Accessing Ozone S3 via CyberDuck","date":"2025-07-02T00:00:00.000Z","authors":["apache-ozone-community"],"tags":["Ozone","S3","CyberDuck"]},"unlisted":false,"prevItem":{"title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","permalink":"/blog/2026/01/29/disk-balancer-preview"},"nextItem":{"title":"Apache Ozone 2.0.0 Release","permalink":"/blog/2025/04/30/ozone-2.0.0-release"}},"content":"Here\'s a step\u2011by\u2011step guide to mounting and managing your Apache Ozone object store\'s S3 interface using CyberDuck.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Prerequisites\\n\\n1. **Running Ozone S3 Gateway**\\n   Make sure your Ozone cluster is up and the S3 Gateway (s3g) is running. By default it listens on port **9878** over HTTP (and 9879 for HTTPS) at the host where you started it.\\n\\n2. **Credentials**\\n   - **No security:** You can use any values for AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY.\\n   - **With Kerberos security enabled:**\\n\\n     ```bash\\n     kinit -kt /etc/security/keytabs/<user>.keytab <user>@YOUR.REALM\\n     ozone s3 getsecret\\n     # \u2192 awsAccessKey=<user>@YOUR.REALM\\n     #   awsSecret=<long\u2011hex\u2011string>\\n     ```\\n\\n   These exports give you the Access Key ID and Secret you\'ll plug into CyberDuck.\\n\\n---\\n\\n## 1. Install CyberDuck\\n\\n1. Download CyberDuck from https://cyberduck.io and install it on your Mac or Windows machine.\\n2. Launch CyberDuck.\\n\\n---\\n\\n## 2. Create a New S3 Connection\\n\\n1. The bundled S3 profile in CyberDuck does not permit a custom network port, and does not allow HTTP. You may need to install additional profiles to allow those.\\n   1. Select a profile from [Ozone S3 CyberDuck profiles](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-cyberduck-profiles-md).\\n   2. For example, download the **[Ozone S3 `HTTP.cyberduckprofile`](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-http-cyberduckprofile)** if your gateway is HTTP.\\n   3. Or download the **[Ozone S3 (HTTP) with path-style `addressing.cyberduckprofile`](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-http-with-path-style-addressing-cyberduckprofile)**.\\n   4. Installing the file by double-clicking a `.cyberduckprofile` file\\n   5. Check out the [CyberDuck user documentation](https://docs.cyberduck.io/protocols/s3) for more details.\\n2. In CyberDuck, click **Open Connection** (or press \u2318 N).\\n3. From the **Protocol** dropdown choose **Ozone S3 (HTTP)** if your gateway is configured for HTTP), or **Apache Ozone S3 HTTP path style** if the gateway is configured with Path-Style Addressing.\\n4. Fill in the fields:\\n   - **Server:** `<ozone\u2011s3\u2011host>` (e.g. `ozone.example.com`)\\n   - **Port:** `9878` (or `9879` for HTTPS)\\n   - **Access Key ID:** the `awsAccessKey` you obtained\\n   - **Secret Access Key:** the `awsSecret` you obtained\\n5. Click the little **\u25b6** triangle next to **More Options** and ensure **Use SSL** is unchecked if you\'re connecting over plain HTTP.\\n6. **Path\u2011Style Addressing** (default) vs **Virtual\u2011Host Style**:\\n   - By default Ozone uses **path\u2011style** (`http://host:9878/bucket`).\\n   - If you\'ve set `ozone.s3g.domain.name` in your `ozone-site.xml`, you can switch to virtual\u2011host style and CyberDuck will use `bucket.host:9878` URLs.\\n\\n---\\n\\n## 3. Save as a Bookmark (Optional)\\n\\n1. Click the dropdown arrow next to the **Connect** button and choose **Bookmark** \u25b6 **Add Bookmark**.\\n2. Give it a name like \\"Ozone S3\\" so you can reconnect quickly.\\n\\n---\\n\\n## 4. Browsing and Basic Operations\\n\\nOnce connected, your CyberDuck window will list all buckets in the default `/s3v` volume as top\u2011level entries.\\n\\n- **List Buckets:** All existing buckets appear as folders.\\n- **Create Bucket:** Click the \\"+\\" (New Folder) icon, enter a bucket name, and press **Return**.\\n- **Upload Files:** Drag\u2011and\u2011drop files from your desktop into a bucket folder.\\n- **Download Files:** Right\u2011click an object and choose **Download To\u2026**\\n- **Delete Objects/Buckets:** Select the file or bucket, press the **Delete** key, and confirm.\\n\\n---\\n\\n## 5. Working with Other Volumes\\n\\nOzone\'s namespace includes volumes beyond `/s3v`. To expose a bucket from another volume:\\n\\n```shell\\nozone sh volume create /vol1\\nozone sh bucket create /vol1/bucket1\\nozone sh bucket link /vol1/bucket1 /s3v/common-bucket\\n```\\n\\nAfter linking, you\'ll see `common-bucket` in CyberDuck and can manage it just like any other S3 bucket.\\n\\n---\\n\\n## 6. Tips & Troubleshooting\\n\\n- **Permissions:** If you get \\"Access Denied,\\" double\u2011check that you\'ve generated or revoked/re\u2011generated your S3 secret correctly.\\n- **SSL Errors:** If you enable HTTPS on the gateway, make sure you either trust the certificate in CyberDuck or use a CA\u2011signed cert.\\n- **Firewall/Network:** Ensure your machine can reach `<ozone\u2011s3\u2011host>:9878` (e.g. `telnet hostname 9878`).\\n- **Bookmarks Sync:** CyberDuck can sync bookmarks via Dropbox or iCloud so you can share connections across devices.\\n\\n---\\n\\nYou\'re all set! Enjoy browsing and managing your Ozone object store through a familiar S3 GUI."},{"id":"/2025/04/30/ozone-2.0.0-release","metadata":{"permalink":"/blog/2025/04/30/ozone-2.0.0-release","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2025-04-30-ozone-2.0.0-release.md","source":"@site/blog/2025-04-30-ozone-2.0.0-release.md","title":"Apache Ozone 2.0.0 Release","description":"Apache Ozone 2.0.0 was released on April 30th, 2025. This release includes 1700 new features, improvements, and bug fixes on top of Ozone 1.4.","date":"2025-04-30T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"ozone-2.0.0","permalink":"/blog/tags/ozone-2-0-0"}],"readingTime":0.965,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null}],"frontMatter":{"title":"Apache Ozone 2.0.0 Release","date":"2025-04-30T00:00:00.000Z","authors":["apache-ozone-community"],"tags":["release","ozone-2.0.0"]},"unlisted":false,"prevItem":{"title":"Accessing Ozone S3 via CyberDuck","permalink":"/blog/2025/07/02/access-ozone-via-cyberduck"}},"content":"Apache Ozone 2.0.0 was released on April 30th, 2025. This release includes 1700 new features, improvements, and bug fixes on top of Ozone 1.4.\\n\\n\x3c!-- truncate --\x3e\\n\\nNotable features in this release include:\\n\\n- Supporting HSync and lease recovery (HDDS-7593).\\n- SCM Decommissioning Support (HDDS-7852).\\n- Symmetric Keys for Delegation Tokens (HDDS-8829).\\n- Atomic Key Overwrite and Key Replacement (HDDS-10656).\\n\\nOther noteworthy changes include:\\n\\n- ARM64 support (HDDS-6263).\\n- Java 11/17/21 Support and Testing (HDDS-8246).\\n- AWS SDK v2 client support (HDDS-12488).\\n\\nObservability improvements are:\\n\\n- Ozone performance and operational dashboards (HDDS-9307).\\n- Recon UI Improvements (HDDS-11153).\\n- Support for interactive mode for Ozone CLI (HDDS-11825).\\n\\nDeveloper-focused changes include:\\n\\n- JUnit 4 to 5 upgrade (HDDS-6729).\\n- Dropped Hadoop 2.7 ~ 2.9 support (HDDS-8113).\\n- Publish SBOM artifacts (HDDS-10986).\\n- Hadoop dependency updated to 3.4.1 (HDDS-11617).\\n\\nIncompatible changes are:\\n\\n- Move S3 Gateway web admin to separate port (HDDS-7307).\\n- Deprecate file per chunk layout from Datanode code (HDDS-11753).\\n- Drop support for non-Ratis OM and SCM (HDDS-11754).\\n- Remove LegacyReplicationManager (HDDS-11759).\\n\\nDetailed release notes are available at https://ozone.apache.org/release/2.0.0/.\\nDownloads can be found at https://ozone.apache.org/downloads/.\\nDocumentation for this release is available at https://ozone.apache.org/docs/2.0.0/."}]}}')}}]);