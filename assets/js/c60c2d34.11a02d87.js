"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[30660],{40475:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"system-internals/replication/data/containers/replication","title":"Container Replication","description":"Overview","source":"@site/docs/07-system-internals/04-replication/02-data/02-containers/08-replication.md","sourceDirName":"07-system-internals/04-replication/02-data/02-containers","slug":"/system-internals/replication/data/containers/replication","permalink":"/docs/next/system-internals/replication/data/containers/replication","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/master/docs/07-system-internals/04-replication/02-data/02-containers/08-replication.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_label":"Replication"},"sidebar":"defaultSidebar","previous":{"title":"Deletion","permalink":"/docs/next/system-internals/replication/data/containers/destruction"},"next":{"title":"Reconstruction","permalink":"/docs/next/system-internals/replication/data/containers/offline-reconstruction"}}');var s=i(86070),r=i(62392);const a={sidebar_label:"Replication"},o="Container Replication",c={},l=[{value:"Overview",id:"overview",level:2},{value:"Replication Mode",id:"replication-mode",level:2},{value:"Detailed Replication Process",id:"detailed-replication-process",level:2},{value:"Step 1: Source Datanode Prepares Container Tarball",id:"step-1-source-datanode-prepares-container-tarball",level:3},{value:"Step 2: Destination Datanode Receives Tarball",id:"step-2-destination-datanode-receives-tarball",level:3},{value:"Step 3: Untar and Store Container Files",id:"step-3-untar-and-store-container-files",level:3},{value:"Step 4: Import Container",id:"step-4-import-container",level:3},{value:"Step 5: Delete Temporary Files",id:"step-5-delete-temporary-files",level:3},{value:"Advantages of Push Replication",id:"advantages-of-push-replication",level:2},{value:"EC Container Replication Scenarios",id:"ec-container-replication-scenarios",level:2},{value:"Scenario 1: Decommissioning",id:"scenario-1-decommissioning",level:3},{value:"Scenario 2: Under-Replication",id:"scenario-2-under-replication",level:3},{value:"Scenario 3: Maintenance Mode",id:"scenario-3-maintenance-mode",level:3},{value:"Scenario 4: Mis-Replication",id:"scenario-4-mis-replication",level:3}];function d(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"container-replication",children:"Container Replication"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Container replication is a critical mechanism in Apache Ozone that ensures data availability and durability by copying containers from source Datanodes to destination Datanodes. This document provides a comprehensive description of the replication process, including the detailed steps involved, advantages of push replication, and scenarios where EC (Erasure Coded) containers can be replicated."}),"\n",(0,s.jsx)(n.h2,{id:"replication-mode",children:"Replication Mode"}),"\n",(0,s.jsxs)(n.p,{children:["Apache Ozone supports ",(0,s.jsx)(n.strong,{children:"Push Replication"})," by ",(0,s.jsx)(n.strong,{children:"default"}),", where the source Datanode actively pushes the container to the target Datanode. The replication mode is controlled by the configuration property ",(0,s.jsx)(n.code,{children:"hdds.scm.replication.push"})," (default: ",(0,s.jsx)(n.code,{children:"true"}),"). When set to ",(0,s.jsx)(n.code,{children:"false"}),", the system uses pull replication where the target Datanode pulls from source Datanodes."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Push Replication :"})," ",(0,s.jsx)(n.code,{children:"PushReplicator"})," class handles push replication by:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Using ",(0,s.jsx)(n.code,{children:"OnDemandContainerReplicationSource"})," to prepare the container"]}),"\n",(0,s.jsxs)(n.li,{children:["Using ",(0,s.jsx)(n.code,{children:"GrpcContainerUploader"})," to upload the container via gRPC stream"]}),"\n",(0,s.jsx)(n.li,{children:"Streaming the container data directly to the target Datanode"}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Both regular container replication and EC container replication respect the same ",(0,s.jsx)(n.code,{children:"hdds.scm.replication.push"})," configuration setting. EC container replication scenarios (decommissioning, under-replication, maintenance mode, mis-replication) will use push mode when the configuration is ",(0,s.jsx)(n.code,{children:"true"})," (default) or pull mode when set to ",(0,s.jsx)(n.code,{children:"false"}),"."]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"detailed-replication-process",children:"Detailed Replication Process"}),"\n",(0,s.jsx)(n.p,{children:"The container replication process involves several well-defined steps."}),"\n",(0,s.jsx)(n.h3,{id:"step-1-source-datanode-prepares-container-tarball",children:"Step 1: Source Datanode Prepares Container Tarball"}),"\n",(0,s.jsx)(n.p,{children:"The source Datanode creates a tarball containing:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Container descriptor file (",(0,s.jsx)(n.code,{children:"container.yaml"}),") with metadata"]}),"\n",(0,s.jsx)(n.li,{children:"RocksDB metadata files (database files)"}),"\n",(0,s.jsx)(n.li,{children:"Container chunk files (actual data)"}),"\n",(0,s.jsx)(n.li,{children:"Container checksum file (if exists)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Compression:"})," This tarball is not compressed by default. Optional compression can be enabled via ",(0,s.jsx)(n.code,{children:"hdds.container.replication.compression"})," (values: ",(0,s.jsx)(n.code,{children:"NO_COMPRESSION"}),"(default), ",(0,s.jsx)(n.code,{children:"GZIP"}),", ",(0,s.jsx)(n.code,{children:"SNAPPY"}),", ",(0,s.jsx)(n.code,{children:"LZ4"}),", ",(0,s.jsx)(n.code,{children:"ZSTD"}),")."]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-destination-datanode-receives-tarball",children:"Step 2: Destination Datanode Receives Tarball"}),"\n",(0,s.jsx)(n.p,{children:"The source Datanode streams the tarball to the destination via gRPC:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Establishes gRPC stream connection"}),"\n",(0,s.jsxs)(n.li,{children:["Streams data in chunks via ",(0,s.jsx)(n.code,{children:"SendContainerRequest"})," messages"]}),"\n",(0,s.jsxs)(n.li,{children:["Destination writes chunks to temporary file in the temp dir of the volume chosen: ",(0,s.jsx)(n.code,{children:"<volume-root>/tmp/container-copy/"}),".\nThat way, Datanode parallelizes container download, and does not block on the system root drive."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Before receiving, the destination selects a volume, ",(0,s.jsx)(n.strong,{children:"reserves space (2x container size)"})," to accommodate both the tarball and the extracted files, and creates the temporary directory."]}),"\n",(0,s.jsx)(n.h3,{id:"step-3-untar-and-store-container-files",children:"Step 3: Untar and Store Container Files"}),"\n",(0,s.jsx)(n.p,{children:"The destination Datanode extracts the tarball:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Reads and verifies container descriptor (",(0,s.jsx)(n.code,{children:"container.yaml"}),")"]}),"\n",(0,s.jsx)(n.li,{children:"Extracts RocksDB metadata to metadata directory"}),"\n",(0,s.jsx)(n.li,{children:"Extracts chunk files to chunks directory"}),"\n",(0,s.jsx)(n.li,{children:"Extracts checksum file (if present) to metadata directory"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Files are extracted to a temporary directory first, then moved atomically to final locations: ",(0,s.jsx)(n.code,{children:"<volume-root>/containerID/"}),", ",(0,s.jsx)(n.code,{children:"<volume-root>/containerID/metadata/"}),", and ",(0,s.jsx)(n.code,{children:"<volume-root>/containerID/chunks/"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"step-4-import-container",children:"Step 4: Import Container"}),"\n",(0,s.jsx)(n.p,{children:"The container is imported into the Datanode's container set:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Creates container object from metadata"}),"\n",(0,s.jsxs)(n.li,{children:["Sets container state to ",(0,s.jsx)(n.code,{children:"RECOVERING"})]}),"\n",(0,s.jsx)(n.li,{children:"Associates container with selected volume"}),"\n",(0,s.jsxs)(n.li,{children:["Adds container to ",(0,s.jsx)(n.code,{children:"ContainerSet"})]}),"\n",(0,s.jsx)(n.li,{children:"Updates volume usage with container size"}),"\n",(0,s.jsx)(n.li,{children:"Schedules on-demand scan"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Import progress is tracked to prevent concurrent imports. If import fails or container already exists, appropriate error handling is performed."}),"\n",(0,s.jsx)(n.h3,{id:"step-5-delete-temporary-files",children:"Step 5: Delete Temporary Files"}),"\n",(0,s.jsx)(n.p,{children:"After successful import, all temporary files are cleaned up:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Delete Tarball"}),": The downloaded tarball file is deleted from the temporary directory"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Release Reserved Space"}),": The reserved space on the volume is released"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cleanup on Failure"}),": If any step fails, temporary files are deleted and reserved space is released"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"advantages-of-push-replication",children:"Advantages of Push Replication"}),"\n",(0,s.jsx)(n.p,{children:"Push replication offers several advantages:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Better Load Distribution"}),": Source Datanode controls transfer rate and timing, managing its own load while simplifying target operations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Improved Network Efficiency"}),": Direct streaming with gRPC flow control adapts to network conditions, reducing latency"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simplified Failure Handling"}),": Source handles retries and error recovery, while targets only process incoming streams"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Better Resource Management"}),": Source can throttle transfers based on its own capacity (disk I/O, CPU, network), preventing overload"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"ec-container-replication-scenarios",children:"EC Container Replication Scenarios"}),"\n",(0,s.jsx)(n.p,{children:"Erasure Coded (EC) containers have specific replication requirements and scenarios where replication is necessary."}),"\n",(0,s.jsx)(n.h3,{id:"scenario-1-decommissioning",children:"Scenario 1: Decommissioning"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"When it occurs:"}),"\nWhen a Datanode enters the decommissioning state, all EC container replicas stored on that Datanode must be replicated to other Datanodes before the Datanode can be safely removed from the cluster."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Detection"}),": ",(0,s.jsx)(n.code,{children:"ECUnderReplicationHandler"})," detects containers with replicas on decommissioning Datanodes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Index Identification"}),": The handler identifies which EC indexes are only present on decommissioning Datanodes (",(0,s.jsx)(n.code,{children:"decommissioningOnlyIndexes()"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"One-to-One Replication"}),": For each decommissioning index, a replication command is created to copy that specific index to a new Datanode"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Target Selection"}),": New target Datanodes are selected based on placement policies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replication Execution"}),": Each index is replicated independently using the configured replication mode (push by default, configurable to pull via ",(0,s.jsx)(n.code,{children:"hdds.scm.replication.push"}),")"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example:"})}),"\n",(0,s.jsxs)(n.p,{children:["For an EC container with replication config ",(0,s.jsx)(n.code,{children:"RS-6-3-1024k"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"6 data blocks + 3 parity blocks = 9 total indexes"}),"\n",(0,s.jsx)(n.li,{children:"If index 2 is only on a decommissioning Datanode, only index 2 needs to be replicated"}),"\n",(0,s.jsxs)(n.li,{children:["The replication command includes ",(0,s.jsx)(n.code,{children:"replicaIndex=2"})," to specify which index to copy"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"scenario-2-under-replication",children:"Scenario 2: Under-Replication"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"When it occurs:"}),"\nWhen an EC container has fewer replicas than required for a specific index, that index needs to be replicated."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replica Count Analysis"}),": ",(0,s.jsx)(n.code,{children:"ECContainerReplicaCount"})," analyzes the current replica distribution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Missing Index Detection"}),": Identifies indexes that have fewer replicas than required"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Source Selection"}),": Selects healthy source replicas for the missing indexes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replication Commands"}),": Creates replication commands to restore redundancy using the configured replication mode (push by default)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"scenario-3-maintenance-mode",children:"Scenario 3: Maintenance Mode"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"When it occurs:"}),"\nWhen Datanodes enter maintenance mode, EC container replicas on those Datanodes may need additional copies to maintain redundancy during maintenance."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,s.jsx)(n.p,{children:"Similar to decommissioning, but with different redundancy requirements:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Maintenance mode allows for reduced redundancy (",(0,s.jsx)(n.code,{children:"maintenanceRemainingRedundancy"})," config)"]}),"\n",(0,s.jsx)(n.li,{children:"Replication ensures minimum redundancy is maintained during maintenance using the configured replication mode (push by default)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"scenario-4-mis-replication",children:"Scenario 4: Mis-Replication"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"When it occurs:"}),"\nWhen EC container replicas are placed on Datanodes that violate placement policies (e.g., too many replicas in the same rack)."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"How it works:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Placement Validation"}),": ",(0,s.jsx)(n.code,{children:"ECMisReplicationHandler"})," validates replica placement against policies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Violation Detection"}),": Identifies replicas that violate placement constraints"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replication to Correct Placement"}),": Creates replication commands to move replicas to compliant locations using the configured replication mode (push by default)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Old Replica Deletion"}),": After successful replication, old replicas are deleted"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},62392:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var t=i(30758);const s={},r=t.createContext(s);function a(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);