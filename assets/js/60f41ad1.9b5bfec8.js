"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[2175],{55493:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/EC-Reads-With-No-Failures-3282015dfe66d9400c33e2c968c5eda6.png"},57997:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/EC-Reconstructional-Read-cb74627ab5163ee8b70a386c62f2327c.png"},62392:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(30758);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}},63796:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/EC-Write-Block-Allocation-in-Containers-4102782ba4d5575f7b788ee28a0d120e.png"},69349:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"core-concepts/replication/erasure-coding","title":"Erasure Coding","description":"Background","source":"@site/docs/03-core-concepts/02-replication/04-erasure-coding.md","sourceDirName":"03-core-concepts/02-replication","slug":"/core-concepts/replication/erasure-coding","permalink":"/docs/core-concepts/replication/erasure-coding","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/docs/03-core-concepts/02-replication/04-erasure-coding.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"Ratis","permalink":"/docs/core-concepts/replication/ratis"},"next":{"title":"Namespace","permalink":"/docs/core-concepts/namespace/"}}');var o=i(86070),s=i(62392);const r={},a="Erasure Coding",c={},l=[{value:"Background",id:"background",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Erasure Coding Write",id:"erasure-coding-write",level:3},{value:"Erasure Coding Read",id:"erasure-coding-read",level:3},{value:"Erasure Coding On-the-fly Reconstruction Reads",id:"erasure-coding-on-the-fly-reconstruction-reads",level:4},{value:"Erasure Coding Replication Config",id:"erasure-coding-replication-config",level:3}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"erasure-coding",children:"Erasure Coding"})}),"\n",(0,o.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,o.jsxs)(n.p,{children:["Distributed systems basic expectation is to provide the data durability.\nTo provide the higher data durability, many popular storage systems use replication\napproach which is expensive. The Apache Ozone supports ",(0,o.jsx)(n.code,{children:"RATIS/THREE"})," replication scheme.\nThe Ozone default replication scheme ",(0,o.jsx)(n.code,{children:"RATIS/THREE"})," has 200% overhead in storage\nspace and other resources (e.g., network bandwidth).\nHowever, for warm and cold datasets with relatively low I/O activities, additional\nblock replicas are rarely accessed during normal operations, but still consume the same\namount of resources as the first replica."]}),"\n",(0,o.jsxs)(n.p,{children:["Therefore, a natural improvement is to use Erasure Coding (EC) in place of replication,\nwhich provides the same level of fault-tolerance with much less storage space.\nIn typical EC setups, the storage overhead is no more than 50%. The replication factor of an EC file is meaningless.\nInstead of replication factor, we introduced ReplicationConfig interface to specify the required type of replication,\neither ",(0,o.jsx)(n.code,{children:"RATIS/THREE"})," or ",(0,o.jsx)(n.code,{children:"EC"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Integrating EC with Ozone can improve storage efficiency while still providing similar\ndata durability as traditional replication-based Ozone deployments.\nAs an example, a 3x replicated file with 6 blocks will consume 6*3 = ",(0,o.jsx)(n.code,{children:"18"})," blocks of disk space.\nBut with EC (6 data, 3 parity) deployment, it will only consume ",(0,o.jsx)(n.code,{children:"9"})," blocks of disk space."]}),"\n",(0,o.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,o.jsx)(n.p,{children:"The storage data layout is a key factor in the implementation of EC. After deep analysis\nand several technical consideration, the most fitting data layout is striping model.\nThe data striping layout is not new. The striping model already adapted by several other\nfile systems(Ex: Quantcast File System, Hadoop Distributed File System etc) successfully before."}),"\n",(0,o.jsx)(n.p,{children:'For example, with the EC (6 data, 3 parity) scheme, the data chunks will be distributed to first 6 data nodes in order\nand then client generates the 3 parity chunks and transfer to remaining 3 nodes in order.\nThese 9 chunks together we call as "Stripe". Next 6 chunks will be distributed to the same first 6 data nodes again\nand the parity to remaining 3 nodes. These 9 data nodes stored blocks together called as "BlockGroup".'}),"\n",(0,o.jsxs)(n.p,{children:["If the application is continuing to write beyond the size of ",(0,o.jsx)(n.code,{children:"6 * BLOCK_SIZE"}),", then client will request new block group from Ozone Manager."]}),"\n",(0,o.jsx)(n.h3,{id:"erasure-coding-write",children:"Erasure Coding Write"}),"\n",(0,o.jsxs)(n.p,{children:["The core logic of erasure coding writes are placed at Ozone client.\nWhen client creates the file, Ozone Manager allocates the block group(",(0,o.jsx)(n.code,{children:"d + p"}),")\nnumber of nodes from the pipeline provider and return the same to client.\nAs data is coming in from the application, client will write first d number of chunks\nto d number of data nodes in block group. It will also cache the d number chunks\nto generate the parity chunks. Once parity chunks generated, it will transfer the\nsame to the remaining p nodes in order. Once all blocks reached their configured sizes,\nclient will request the new block group nodes."]}),"\n",(0,o.jsx)(n.p,{children:"Below diagram depicts the block allocation in containers as logical groups.\nFor interest of space, we assumed EC(3, 2) Replication Config for the diagram."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"EC Block Allocation in Containers",src:i(63796).A+"",width:"720",height:"495"})}),"\n",(0,o.jsx)(n.p,{children:"Let's zoom out the blockID: 1 data layout from the above picture, that showed in the following picture.\nThis picture shows how the chunks will be laid out in data node blocks."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"EC Chunk Layout",src:i(75691).A+"",width:"720",height:"454"})}),"\n",(0,o.jsxs)(n.p,{children:["Currently, the EC client re-used the data transfer end-points to transfer the data to data nodes.\nThe XceiverClientGRPC client used for writing data and putBlock info.\nThe Datanode side changes are minimal as we reused the same existing transfer protocols.\nThe EC data block written at the Datanode is same as any other block in non-EC mode.\nIn a single block group, container id numbers are same in all nodes. A file can have multiple block groups.\nEach block group will have ",(0,o.jsx)(n.code,{children:"d+p"})," number of block and all ids are same."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"d"})," - Number of data blocks in a block group"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"p"})," - Number of parity blocks in a block group"]}),"\n",(0,o.jsx)(n.h3,{id:"erasure-coding-read",children:"Erasure Coding Read"}),"\n",(0,o.jsx)(n.p,{children:"For reads, OM will provide the node location details as part of key lookup.\nIf the key is erasure coded, Ozone client reads it in EC fashion. Since the data layout\nis different(see the previous section about write path), reads should consider the layout and do the reads accordingly."}),"\n",(0,o.jsx)(n.p,{children:"The EC client will open the connections to DNs based on the expected locations. When all data locations are available,\nit will attempt to do plain reads chunk by chunk in round robin fashion from d data blocks."}),"\n",(0,o.jsx)(n.p,{children:"Below picture shows the order when there are no failures while reading."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"EC Reads With no Failures",src:i(55493).A+"",width:"720",height:"456"})}),"\n",(0,o.jsx)(n.p,{children:"Until it sees read failures, there is no need of doing EC reconstruction."}),"\n",(0,o.jsx)(n.h4,{id:"erasure-coding-on-the-fly-reconstruction-reads",children:"Erasure Coding On-the-fly Reconstruction Reads"}),"\n",(0,o.jsx)(n.p,{children:"When client detects there are failures while reading or when starting the reads,\nOzone EC client is capable of reconstructing/recovering the lost data by doing the EC decoding.\nTo do the EC decoding it needs to read parity replicas. This is a degraded read as it needs to do reconstruction.\nThis reconstruction is completely transparent to the applications."}),"\n",(0,o.jsx)(n.p,{children:"Below picture depicts how it uses parity replicas in reconstruction."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"EC Reconstructional Reads",src:i(57997).A+"",width:"720",height:"521"})}),"\n",(0,o.jsx)(n.h3,{id:"erasure-coding-replication-config",children:"Erasure Coding Replication Config"}),"\n",(0,o.jsx)(n.p,{children:"Apache Ozone built with the pure 'Object Storage' semantics. However, many big data\neco system projects still uses file system APIs. To provide both worlds best access to Ozone,\nit's provided both faces of interfaces. In both cases, keys/files would be written into buckets under the hood.\nSo, EC Replication Configs can be set at bucket level.\nThe EC policy encapsulates how to encode/decode a file."}),"\n",(0,o.jsx)(n.p,{children:"Each EC Replication Config defined by the following pieces of information:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"data:"})," Data blocks number in an EC block group."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"parity:"})," Parity blocks number in an EC block group."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ecChunkSize:"})," The size of a striping chunk. This determines the granularity of striped reads and writes."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"codec:"})," This is to indicate the type of EC algorithms (e.g., ",(0,o.jsx)(n.code,{children:"RS"}),"(Reed-Solomon), ",(0,o.jsx)(n.code,{children:"XOR"}),")."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["To pass the EC Replication Config in command line or configuration files, we need to use the following format:\n",(0,o.jsx)(n.em,{children:"codec"}),"-",(0,o.jsx)(n.em,{children:"num data blocks"}),"-",(0,o.jsx)(n.em,{children:"num parity blocks"}),"-",(0,o.jsx)(n.em,{children:"EC chunk size"})]}),"\n",(0,o.jsxs)(n.p,{children:["Currently, there are three built-in EC Replication Configs supported: ",(0,o.jsx)(n.code,{children:"RS-3-2-1024k"}),", ",(0,o.jsx)(n.code,{children:"RS-6-3-1024k"}),", ",(0,o.jsx)(n.code,{children:"XOR-2-1-1024k"}),".\nThe most recommended option is ",(0,o.jsx)(n.code,{children:"RS-6-3-1024k"}),". When a key/file created without specifying the Replication Config,\nit inherits the EC Replication Config of its bucket if it's available."]}),"\n",(0,o.jsx)(n.p,{children:"Changing the bucket level EC Replication Config only affect new files created within the bucket.\nOnce a file has been created, its EC Replication Config cannot be changed currently."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},75691:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/EC-Chunk-Layout-a02f386de80189b7a93d59273b6d9a4c.png"}}]);