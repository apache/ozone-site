"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[7242],{62392:(e,i,t)=>{t.d(i,{R:()=>a,x:()=>l});var n=t(30758);const r={},o=n.createContext(r);function a(e){const i=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(o.Provider,{value:i},e.children)}},96144:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"administrator-guide/configuration/high-availability/client-failover","title":"HA Client Failover","description":"Overview","source":"@site/docs/05-administrator-guide/02-configuration/06-high-availability/03-client-failover.md","sourceDirName":"05-administrator-guide/02-configuration/06-high-availability","slug":"/administrator-guide/configuration/high-availability/client-failover","permalink":"/docs/next/administrator-guide/configuration/high-availability/client-failover","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/master/docs/05-administrator-guide/02-configuration/06-high-availability/03-client-failover.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_label":"Client Failover"},"sidebar":"defaultSidebar","previous":{"title":"OM HA Configuration","permalink":"/docs/next/administrator-guide/configuration/high-availability/om-ha"},"next":{"title":"Operations","permalink":"/docs/next/administrator-guide/operations/"}}');var r=t(86070),o=t(62392);const a={sidebar_label:"Client Failover"},l="HA Client Failover",s={},d=[{value:"Overview",id:"overview",level:2},{value:"Client to Ozone Manager Failover",id:"client-to-ozone-manager-failover",level:2},{value:"1. Hadoop RPC Transport (<code>HadoopRpcOMFailoverProxyProvider</code>)",id:"1-hadoop-rpc-transport-hadooprpcomfailoverproxyprovider",level:3},{value:"2. gRPC Transport",id:"2-grpc-transport",level:3},{value:"Client to Storage Container Manager Failover",id:"client-to-storage-container-manager-failover",level:2},{value:"Client to Datanode Failover and Retry",id:"client-to-datanode-failover-and-retry",level:2}];function c(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"ha-client-failover",children:"HA Client Failover"})}),"\n",(0,r.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(i.p,{children:"This document describes how Ozone clients handle failover and retry logic to ensure high availability and reliability. In Ozone's high availability (HA) setup, clients need to automatically failover between multiple service instances (Ozone Manager, Storage Container Manager) and retry operations when encountering failures with Datanodes."}),"\n",(0,r.jsx)(i.p,{children:"The failover and retry mechanisms operate transparently to client applications. Clients automatically detect failures, switch to alternative service instances, and retry operations according to configurable policies. An exception is only raised to the application layer after all retry attempts have been exhausted."}),"\n",(0,r.jsx)(i.h2,{id:"client-to-ozone-manager-failover",children:"Client to Ozone Manager Failover"}),"\n",(0,r.jsxs)(i.p,{children:["Clients always submit requests to the leader Ozone Manager (OM). If the ",(0,r.jsx)(i.code,{children:"leader"})," is ",(0,r.jsx)(i.code,{children:"unknown"}),", clients start by sending requests to the first OM in the configuration and retries other OMs until a leader is found."]}),"\n",(0,r.jsxs)(i.h3,{id:"1-hadoop-rpc-transport-hadooprpcomfailoverproxyprovider",children:["1. Hadoop RPC Transport (",(0,r.jsx)(i.code,{children:"HadoopRpcOMFailoverProxyProvider"}),")"]}),"\n",(0,r.jsxs)(i.p,{children:["If client to OM is Hadoop RPC transport(",(0,r.jsx)(i.code,{children:"HadoopRpcOMFailoverProxyProvider"}),"), failover or retry may happen if the OM:"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"is not reachable,"}),"\n",(0,r.jsx)(i.li,{children:"is not the leader, or"}),"\n",(0,r.jsx)(i.li,{children:"is the leader but not ready to accept requests."}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["The failover mechanism retries up to ",(0,r.jsx)(i.strong,{children:"500 times"})," (",(0,r.jsx)(i.code,{children:"ozone.client.failover.max.attempts"}),"), with ",(0,r.jsx)(i.strong,{children:"2 seconds"})," between each failover retry (",(0,r.jsx)(i.code,{children:"ozone.client.wait.between.retries.millis"}),").\nIf an OM is not aware of the current leader, the client tries the next OM in round-robin fashion. Otherwise, the client retries contacting the current leader."]}),"\n",(0,r.jsx)(i.p,{children:"Additionally, it is crucial to ensure clients and OM have consistent node mapping configurations, otherwise failover may not reach the leader OM."}),"\n",(0,r.jsx)(i.h3,{id:"2-grpc-transport",children:"2. gRPC Transport"}),"\n",(0,r.jsxs)(i.p,{children:["When using gRPC transport (",(0,r.jsx)(i.code,{children:"GrpcOMFailoverProxyProvider"}),"), the failover behavior is similar to Hadoop RPC transport, using the same retry policies and configuration parameters."]}),"\n",(0,r.jsx)(i.h2,{id:"client-to-storage-container-manager-failover",children:"Client to Storage Container Manager Failover"}),"\n",(0,r.jsxs)(i.p,{children:["Client (client, OM, or Datanode) to SCM failover is controlled by configuration properties in ",(0,r.jsx)(i.code,{children:"SCMClientConfig"}),". Clients try to connect to the leader SCM.\nIf the SCM provides a suggested leader in the exception, the client fails over to that leader. Otherwise, the client tries the next SCM in round-robin fashion."]}),"\n",(0,r.jsx)(i.p,{children:"The failover configuration properties are:"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Property"}),(0,r.jsx)(i.th,{children:"Default"}),(0,r.jsx)(i.th,{children:"Description"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"hdds.scmclient.rpc.timeout"})}),(0,r.jsx)(i.td,{children:"15min"}),(0,r.jsxs)(i.td,{children:["RPC timeout for SCM. If ",(0,r.jsx)(i.code,{children:"ipc.client.ping"})," is set to true and this RPC-timeout is greater than the value of ",(0,r.jsx)(i.code,{children:"ipc.ping.interval"}),", the effective value of the RPC-timeout is rounded up to multiple of ",(0,r.jsx)(i.code,{children:"ipc.ping.interval"}),"."]})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"hdds.scmclient.max.retry.timeout"})}),(0,r.jsx)(i.td,{children:"10min"}),(0,r.jsx)(i.td,{children:"Maximum retry timeout for SCM Client."})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"hdds.scmclient.failover.max.retry"})}),(0,r.jsx)(i.td,{children:"15"}),(0,r.jsxs)(i.td,{children:["Maximum retry count for SCM Client when failover happens. If ",(0,r.jsx)(i.code,{children:"maxRetryTimeout / retryInterval"})," is larger than this value, the calculated value is used instead."]})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"hdds.scmclient.failover.retry.interval"})}),(0,r.jsx)(i.td,{children:"2s"}),(0,r.jsx)(i.td,{children:"Time to wait between retry attempts to other SCM IP."})]})]})]}),"\n",(0,r.jsx)(i.h2,{id:"client-to-datanode-failover-and-retry",children:"Client to Datanode Failover and Retry"}),"\n",(0,r.jsx)(i.p,{children:"Clients retry Datanodes in the pipeline in order upon failure, in other words clients attempting to access a block belonging to a Ratis/3 pipeline may retry up to 3 Datanodes. The retry behavior differs for read and write operations:"}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.strong,{children:"Read Operations:"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Clients retry each Datanode 3 times (",(0,r.jsx)(i.code,{children:"ozone.client.read.max.retries"}),")"]}),"\n",(0,r.jsxs)(i.li,{children:["1 second pause between retries (",(0,r.jsx)(i.code,{children:"ozone.client.read.retry.interval"}),")"]}),"\n",(0,r.jsxs)(i.li,{children:["Maximum retries: ",(0,r.jsx)(i.strong,{children:"3 \xd7 number of Datanodes"})]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.strong,{children:"Write Operations:"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Clients retry each Datanode 5 times (",(0,r.jsx)(i.code,{children:"ozone.client.max.retries"}),")"]}),"\n",(0,r.jsxs)(i.li,{children:["No pause between retries (",(0,r.jsx)(i.code,{children:"ozone.client.retry.interval"}),", default: 0)"]}),"\n",(0,r.jsxs)(i.li,{children:["Maximum retries: ",(0,r.jsx)(i.strong,{children:"5 \xd7 number of Datanodes"})]}),"\n"]}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Property"}),(0,r.jsx)(i.th,{children:"Default"}),(0,r.jsx)(i.th,{children:"Description"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"ozone.client.read.max.retries"})}),(0,r.jsx)(i.td,{children:"3"}),(0,r.jsx)(i.td,{children:"Maximum number of retries by Ozone Client on encountering connectivity exception when reading a key."})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"ozone.client.read.retry.interval"})}),(0,r.jsx)(i.td,{children:"1 second"}),(0,r.jsx)(i.td,{children:"Time duration in seconds a client will wait before retrying a read key request on encountering a connectivity exception from Datanodes."})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"ozone.client.max.retries"})}),(0,r.jsx)(i.td,{children:"5"}),(0,r.jsx)(i.td,{children:"Maximum number of retries by Ozone Client on encountering exception while writing a key."})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"ozone.client.retry.interval"})}),(0,r.jsx)(i.td,{children:"0"}),(0,r.jsx)(i.td,{children:"Time duration a client will wait before retrying a write key request on encountering an exception. By default there is no wait."})]})]})]})]})}function h(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);