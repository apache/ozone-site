"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2026/01/29/disk-balancer-preview","metadata":{"permalink":"/blog/2026/01/29/disk-balancer-preview","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2026-01-29-disk-balancer-preview.md","source":"@site/blog/2026-01-29-disk-balancer-preview.md","title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","description":"Ever replaced a drive on a Datanode only to watch it become an I/O hotspot?","date":"2026-01-29T00:00:00.000Z","tags":[{"inline":true,"label":"Ozone","permalink":"/blog/tags/ozone"},{"inline":true,"label":"Disk Balancer","permalink":"/blog/tags/disk-balancer"},{"inline":true,"label":"Ozone 2.2","permalink":"/blog/tags/ozone-2-2"},{"inline":true,"label":"Datanode","permalink":"/blog/tags/datanode"}],"readingTime":4.835,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null},{"name":"Wei-Chiu Chuang","title":"Apache Ozone PMC","url":"https://github.com/jojochuang","imageURL":"https://github.com/jojochuang.png","key":"jojochuang","page":null},{"name":"Yu-Chen Lai","title":"Apache Ozone Contributor","url":"https://github.com/0lai0","imageURL":"https://github.com/0lai0.png","key":"0lai0","page":null},{"name":"Gargi Jaiswal","title":"Apache Ozone Contributor","url":"https://github.com/Gargi-jais11","imageURL":"https://github.com/Gargi-jais11.png","key":"Gargi-jais11","page":null}],"frontMatter":{"title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","authors":["apache-ozone-community","jojochuang","0lai0","Gargi-jais11"],"date":"2026-01-29T00:00:00.000Z","tags":["Ozone","Disk Balancer","Ozone 2.2","Datanode"]},"unlisted":false,"nextItem":{"title":"Accessing Ozone S3 via CyberDuck","permalink":"/blog/2025/07/02/access-ozone-via-cyberduck"}},"content":"Ever replaced a drive on a Datanode only to watch it become an I/O hotspot?\\nOr seen one disk hit 95% usage while others on the same machine sit idle?\\nThese imbalances create performance bottlenecks and increase failure risk.\\nApache Ozone\'s new intra-node Disk Balancer is designed to fix this\u2014automatically.\\n\\n\x3c!-- truncate --\x3e\\n\\nCluster-wide balancing in Ozone already ensures replicas are evenly spread across Datanodes. But inside a single Datanode, disks can still drift out of balance over time \u2014 for example after adding new disks, replacing hardware, or performing large deletions. This leads to I/O hotspots and uneven wear.\\n\\nDisk Balancer closes that gap.\\n\\n## Why Disk Balancer?\\n\\n- **Disks fill unevenly** when nodes gain or lose volumes.\\n\\n- **Large deletes** can empty some disks disproportionately.\\n\\n- **Hot disks degrade performance** and become failure risks.\\n\\nEven if the cluster is balanced, the node itself may not be. Disk Balancer fixes this automatically.\\n\\n## How it works\\n\\nThe design ([HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)) introduces a simple metric: **Volume Data Density** \u2014 how much a disk\'s utilization deviates from the node\'s average. If the deviation exceeds a threshold, the node begins balancing.\\n\\nBalancing is local and safe:\\n\\n- Only **closed containers** are moved.\\n- Moves happen entirely **within the same Datanode.**\\n- A scheduler periodically checks for imbalance and dispatches copy-and-import tasks.\\n- Bandwidth and concurrency are **operator-tunable** to avoid interfering with production I/O.\\n\\nThis runs independently on each Datanode. To use it, first enable the feature by setting `hdds.datanode.disk.balancer.enabled = true` in `ozone-site.xml` on your Datanodes. Once enabled, clients use `ozone admin datanode diskbalancer` commands to talk directly to Datanodes, with SCM only used to discover IN_SERVICE Datanodes when running batch operations with `--in-service-datanodes`.\\n\\n## How DiskBalancer Decides What to Move\\n\\nDiskBalancer uses simple but robust policies to decide **which disks to balance** and **which containers to move** (see the design doc for details: `diskbalancer.md` in [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)).\\n\\n- **Default Volume Choosing Policy**: Picks the most over\u2011utilized volume as the source and the most under\u2011utilized volume as the destination, based on each disk\u2019s **Volume Data Density** and the Datanode\u2019s average utilization.\\n- **Default Container Choosing Policy**: Scans containers on the source volume and moves only **CLOSED** containers that are not already being moved. To avoid repeatedly scanning the same list, it caches container metadata with automatic expiry.\\n\\nThese defaults aim to make safe, incremental moves that converge the disks toward an even utilization state.\\n\\n### Container Move Process\\n\\nWhen DiskBalancer moves a container from one disk to another on the **same Datanode**, it follows a careful **\\"Copy-Validate-Replace\\"** flow (summarized from the design doc for [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)):\\n\\n1. Create a temporary copy of the CLOSED container on the destination disk.\\n2. Transition that copy into a **RECOVERING** state and import it as a new container on the destination.\\n3. Once import and metadata updates succeed, delete the original CLOSED container from the source disk.\\n\\nThis ensures that data is always consistent: the destination copy is fully validated before the original is removed, minimizing risk during balancing.\\n\\n## Using Disk Balancer\\n\\nFirst, enable the Disk Balancer feature on each Datanode by setting the following in `ozone-site.xml`:\\n\\n- `hdds.datanode.disk.balancer.enabled = true`\\n\\nThe Disk Balancer CLI supports two command patterns:\\n\\n- `ozone admin datanode diskbalancer <command> --in-service-datanodes` - Operate on all **IN_SERVICE and HEALTHY** Datanodes\\n- `ozone admin datanode diskbalancer <command> <dn-hostname/dn-ipaddress:port>` - Operate on a specific Datanode\\n\\nAvailable commands:\\n\\n- **start** - Start the Disk Balancer on the target Datanode(s)\\n- **stop** - Stop the Disk Balancer on the target Datanode(s)\\n- **status** - Check the current Disk Balancer status\\n- **report** - Get a volume density report showing imbalance across disks\\n- **update** - Update Disk Balancer configuration settings\\n\\nExamples:\\n\\n```bash\\n# Start Disk Balancer\\nozone admin datanode diskbalancer start --in-service-datanodes\\nor\\nozone admin datanode diskbalancer start ozone-datanode-1 ozone-datanode-5\\n\\n# user can also specifiy configuration parameters during start\\nozone admin datanode diskbalancer start -t <value> -b <value> -p <value> -s <value> --in-service-datanodes\\nor\\nozone admin datanode diskbalancer start -t <value> -b <value> -p <value> -s <value> ozone-datanode-1\\n\\n# Stop Disk Balancer\\nozone admin datanode diskbalancer stop --in-service-datanodes\\nor\\nozone admin datanode diskbalancer stop 192.168.1.100:9860\\n\\n# Check status\\nozone admin datanode diskbalancer status --in-service-datanodes\\nor\\nozone admin datanode diskbalancer status ozone-datanode-1\\n\\n# Get volume density report\\nozone admin datanode diskbalancer report --in-service-datanodes\\nor\\nozone admin datanode diskbalancer report 192.168.1.100:9860\\n\\n# Update configuration\\nozone admin datanode diskbalancer update -t <value> -b <value> -p <value> -s <value> --in-service-datanodes\\nor\\nozone admin datanode diskbalancer update -t <value> -b <value> -p <value> -s <value> ozone-datanode-1\\n```\\n\\n### Configuration Parameters\\n\\nThe following parameters can be specified during **start** or **update configuration** Disk Balancer:\\n\\n| Parameter | Short Flag | Default Value | Description |\\n| --------- | ---------- |---------------| ----------- |\\n| `--threshold` | `-t` | `10.0`        | Percentage deviation from average utilization of the disks after which a Datanode will be rebalanced. |\\n| `--bandwidth-in-mb` | `-b` | `10`          | Maximum bandwidth for DiskBalancer per second. |\\n| `--parallel-thread` | `-p` | `5`           | Max parallel thread count for DiskBalancer. |\\n| `--stop-after-disk-even` | `-s` | `true`        | Stop DiskBalancer automatically after disk utilization is even. |\\n\\n## Benefits for operators\\n\\n- **Even I/O load** across disks \u2192 more stable performance.\\n- **Smooth ops after hardware changes** (new or replaced disks).\\n- **Hands-off balancing** once enabled.\\n- **Clear metrics** for observability and troubleshooting.\\n\\nIt complements the existing Container Balancer: one works across nodes, the other within nodes.\\n\\n## Closing Thoughts\\n\\nDisk Balancer is small but impactful. It brings Ozone closer to being a fully self-healing, self-balancing object store \u2014 reducing hotspots, simplifying maintenance, and improving cluster longevity.\\n\\nOzone 2.2 will ship with this feature available via simple CLI controls and safe defaults. If you run long-lived clusters, this is a feature to watch.\\n\\nFor more information, check out [HDDS-5713](https://issues.apache.org/jira/browse/HDDS-5713)."},{"id":"/2025/07/02/access-ozone-via-cyberduck","metadata":{"permalink":"/blog/2025/07/02/access-ozone-via-cyberduck","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2025-07-02-access-ozone-via-cyberduck.md","source":"@site/blog/2025-07-02-access-ozone-via-cyberduck.md","title":"Accessing Ozone S3 via CyberDuck","description":"Here\'s a step\u2011by\u2011step guide to mounting and managing your Apache Ozone object store\'s S3 interface using CyberDuck.","date":"2025-07-02T00:00:00.000Z","tags":[{"inline":true,"label":"Ozone","permalink":"/blog/tags/ozone"},{"inline":true,"label":"S3","permalink":"/blog/tags/s-3"},{"inline":true,"label":"CyberDuck","permalink":"/blog/tags/cyber-duck"}],"readingTime":3.095,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null}],"frontMatter":{"title":"Accessing Ozone S3 via CyberDuck","date":"2025-07-02T00:00:00.000Z","authors":["apache-ozone-community"],"tags":["Ozone","S3","CyberDuck"]},"unlisted":false,"prevItem":{"title":"No More Hotspots: Introducing the Automatic Disk Balancer in Apache Ozone","permalink":"/blog/2026/01/29/disk-balancer-preview"},"nextItem":{"title":"Apache Ozone 2.0.0 Release","permalink":"/blog/2025/04/30/ozone-2.0.0-release"}},"content":"Here\'s a step\u2011by\u2011step guide to mounting and managing your Apache Ozone object store\'s S3 interface using CyberDuck.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Prerequisites\\n\\n1. **Running Ozone S3 Gateway**\\n   Make sure your Ozone cluster is up and the S3 Gateway (s3g) is running. By default it listens on port **9878** over HTTP (and 9879 for HTTPS) at the host where you started it.\\n\\n2. **Credentials**\\n   - **No security:** You can use any values for AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY.\\n   - **With Kerberos security enabled:**\\n\\n     ```bash\\n     kinit -kt /etc/security/keytabs/<user>.keytab <user>@YOUR.REALM\\n     ozone s3 getsecret\\n     # \u2192 awsAccessKey=<user>@YOUR.REALM\\n     #   awsSecret=<long\u2011hex\u2011string>\\n     ```\\n\\n   These exports give you the Access Key ID and Secret you\'ll plug into CyberDuck.\\n\\n---\\n\\n## 1. Install CyberDuck\\n\\n1. Download CyberDuck from https://cyberduck.io and install it on your Mac or Windows machine.\\n2. Launch CyberDuck.\\n\\n---\\n\\n## 2. Create a New S3 Connection\\n\\n1. The bundled S3 profile in CyberDuck does not permit a custom network port, and does not allow HTTP. You may need to install additional profiles to allow those.\\n   1. Select a profile from [Ozone S3 CyberDuck profiles](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-cyberduck-profiles-md).\\n   2. For example, download the **[Ozone S3 `HTTP.cyberduckprofile`](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-http-cyberduckprofile)** if your gateway is HTTP.\\n   3. Or download the **[Ozone S3 (HTTP) with path-style `addressing.cyberduckprofile`](https://gist.github.com/jojochuang/9e15acee99b528ee879f7a280b8f79f7#file-ozone-s3-http-with-path-style-addressing-cyberduckprofile)**.\\n   4. Installing the file by double-clicking a `.cyberduckprofile` file\\n   5. Check out the [CyberDuck user documentation](https://docs.cyberduck.io/protocols/s3) for more details.\\n2. In CyberDuck, click **Open Connection** (or press \u2318 N).\\n3. From the **Protocol** dropdown choose **Ozone S3 (HTTP)** if your gateway is configured for HTTP), or **Apache Ozone S3 HTTP path style** if the gateway is configured with Path-Style Addressing.\\n4. Fill in the fields:\\n   - **Server:** `<ozone\u2011s3\u2011host>` (e.g. `ozone.example.com`)\\n   - **Port:** `9878` (or `9879` for HTTPS)\\n   - **Access Key ID:** the `awsAccessKey` you obtained\\n   - **Secret Access Key:** the `awsSecret` you obtained\\n5. Click the little **\u25b6** triangle next to **More Options** and ensure **Use SSL** is unchecked if you\'re connecting over plain HTTP.\\n6. **Path\u2011Style Addressing** (default) vs **Virtual\u2011Host Style**:\\n   - By default Ozone uses **path\u2011style** (`http://host:9878/bucket`).\\n   - If you\'ve set `ozone.s3g.domain.name` in your `ozone-site.xml`, you can switch to virtual\u2011host style and CyberDuck will use `bucket.host:9878` URLs.\\n\\n---\\n\\n## 3. Save as a Bookmark (Optional)\\n\\n1. Click the dropdown arrow next to the **Connect** button and choose **Bookmark** \u25b6 **Add Bookmark**.\\n2. Give it a name like \\"Ozone S3\\" so you can reconnect quickly.\\n\\n---\\n\\n## 4. Browsing and Basic Operations\\n\\nOnce connected, your CyberDuck window will list all buckets in the default `/s3v` volume as top\u2011level entries.\\n\\n- **List Buckets:** All existing buckets appear as folders.\\n- **Create Bucket:** Click the \\"+\\" (New Folder) icon, enter a bucket name, and press **Return**.\\n- **Upload Files:** Drag\u2011and\u2011drop files from your desktop into a bucket folder.\\n- **Download Files:** Right\u2011click an object and choose **Download To\u2026**\\n- **Delete Objects/Buckets:** Select the file or bucket, press the **Delete** key, and confirm.\\n\\n---\\n\\n## 5. Working with Other Volumes\\n\\nOzone\'s namespace includes volumes beyond `/s3v`. To expose a bucket from another volume:\\n\\n```shell\\nozone sh volume create /vol1\\nozone sh bucket create /vol1/bucket1\\nozone sh bucket link /vol1/bucket1 /s3v/common-bucket\\n```\\n\\nAfter linking, you\'ll see `common-bucket` in CyberDuck and can manage it just like any other S3 bucket.\\n\\n---\\n\\n## 6. Tips & Troubleshooting\\n\\n- **Permissions:** If you get \\"Access Denied,\\" double\u2011check that you\'ve generated or revoked/re\u2011generated your S3 secret correctly.\\n- **SSL Errors:** If you enable HTTPS on the gateway, make sure you either trust the certificate in CyberDuck or use a CA\u2011signed cert.\\n- **Firewall/Network:** Ensure your machine can reach `<ozone\u2011s3\u2011host>:9878` (e.g. `telnet hostname 9878`).\\n- **Bookmarks Sync:** CyberDuck can sync bookmarks via Dropbox or iCloud so you can share connections across devices.\\n\\n---\\n\\nYou\'re all set! Enjoy browsing and managing your Ozone object store through a familiar S3 GUI."},{"id":"/2025/04/30/ozone-2.0.0-release","metadata":{"permalink":"/blog/2025/04/30/ozone-2.0.0-release","editUrl":"https://github.com/apache/ozone-site/tree/HDDS-9225-website-v2/blog/2025-04-30-ozone-2.0.0-release.md","source":"@site/blog/2025-04-30-ozone-2.0.0-release.md","title":"Apache Ozone 2.0.0 Release","description":"Apache Ozone 2.0.0 was released on April 30th, 2025. This release includes 1700 new features, improvements, and bug fixes on top of Ozone 1.4.","date":"2025-04-30T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"ozone-2.0.0","permalink":"/blog/tags/ozone-2-0-0"}],"readingTime":0.965,"hasTruncateMarker":true,"authors":[{"name":"The Apache Ozone Community","title":"Apache Ozone Project","url":"https://ozone.apache.org","imageURL":"/img/ozone-logo.svg","key":"apache-ozone-community","page":null}],"frontMatter":{"title":"Apache Ozone 2.0.0 Release","date":"2025-04-30T00:00:00.000Z","authors":["apache-ozone-community"],"tags":["release","ozone-2.0.0"]},"unlisted":false,"prevItem":{"title":"Accessing Ozone S3 via CyberDuck","permalink":"/blog/2025/07/02/access-ozone-via-cyberduck"}},"content":"Apache Ozone 2.0.0 was released on April 30th, 2025. This release includes 1700 new features, improvements, and bug fixes on top of Ozone 1.4.\\n\\n\x3c!-- truncate --\x3e\\n\\nNotable features in this release include:\\n\\n- Supporting HSync and lease recovery (HDDS-7593).\\n- SCM Decommissioning Support (HDDS-7852).\\n- Symmetric Keys for Delegation Tokens (HDDS-8829).\\n- Atomic Key Overwrite and Key Replacement (HDDS-10656).\\n\\nOther noteworthy changes include:\\n\\n- ARM64 support (HDDS-6263).\\n- Java 11/17/21 Support and Testing (HDDS-8246).\\n- AWS SDK v2 client support (HDDS-12488).\\n\\nObservability improvements are:\\n\\n- Ozone performance and operational dashboards (HDDS-9307).\\n- Recon UI Improvements (HDDS-11153).\\n- Support for interactive mode for Ozone CLI (HDDS-11825).\\n\\nDeveloper-focused changes include:\\n\\n- JUnit 4 to 5 upgrade (HDDS-6729).\\n- Dropped Hadoop 2.7 ~ 2.9 support (HDDS-8113).\\n- Publish SBOM artifacts (HDDS-10986).\\n- Hadoop dependency updated to 3.4.1 (HDDS-11617).\\n\\nIncompatible changes are:\\n\\n- Move S3 Gateway web admin to separate port (HDDS-7307).\\n- Deprecate file per chunk layout from Datanode code (HDDS-11753).\\n- Drop support for non-Ratis OM and SCM (HDDS-11754).\\n- Remove LegacyReplicationManager (HDDS-11759).\\n\\nDetailed release notes are available at https://ozone.apache.org/release/2.0.0/.\\nDownloads can be found at https://ozone.apache.org/downloads/.\\nDocumentation for this release is available at https://ozone.apache.org/docs/2.0.0/."}]}}')}}]);