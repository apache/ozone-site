"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[9571],{44729:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"user-guide/integrations/iceberg","title":"Apache Iceberg","description":"Apache Iceberg is an open table format for huge analytic datasets. It is designed to improve on the limitations of traditional table formats like Hive and provides features such as schema evolution, hidden partitioning, and time travel.","source":"@site/versioned_docs/version-2.1.0/04-user-guide/03-integrations/03-iceberg.md","sourceDirName":"04-user-guide/03-integrations","slug":"/user-guide/integrations/iceberg","permalink":"/docs/user-guide/integrations/iceberg","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/master/versioned_docs/version-2.1.0/04-user-guide/03-integrations/03-iceberg.md","tags":[],"version":"2.1.0","sidebarPosition":3,"frontMatter":{"sidebar_label":"Iceberg"},"sidebar":"defaultSidebar","previous":{"title":"Hue","permalink":"/docs/user-guide/integrations/hue"},"next":{"title":"Impala","permalink":"/docs/user-guide/integrations/impala"}}');var a=s(86070),r=s(62392);const o={sidebar_label:"Iceberg"},i="Apache Iceberg",c={},d=[{value:"Key Integration Details",id:"key-integration-details",level:2},{value:"Quickstart",id:"quickstart",level:2},{value:"Quickstart environment",id:"quickstart-environment",level:3},{value:"Step 1 \u2014 Create <code>docker-compose.yaml</code> for Ozone services",id:"step-1--create-docker-composeyaml-for-ozone-services",level:3},{value:"Step 2 \u2014 Create <code>iceberg-spark.yml</code> for Iceberg services",id:"step-2--create-iceberg-sparkyml-for-iceberg-services",level:3},{value:"Step 3 \u2014 Start Iceberg and Ozone together",id:"step-3--start-iceberg-and-ozone-together",level:3},{value:"Step 4 \u2014 Start a Spark SQL client",id:"step-4--start-a-spark-sql-client",level:3},{value:"Step 5 \u2014 Create and Query a table backed by Ozone S3",id:"step-5--create-and-query-a-table-backed-by-ozone-s3",level:3}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"apache-iceberg",children:"Apache Iceberg"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://iceberg.apache.org/",children:"Apache Iceberg"})," is an open table format for huge analytic datasets. It is designed to improve on the limitations of traditional table formats like Hive and provides features such as schema evolution, hidden partitioning, and time travel."]}),"\n",(0,a.jsx)(n.p,{children:"Iceberg uses Ozone storage layer to build scalable data lakehouses, acting as the durable system of record for table data and metadata. Ozone\u2019s native atomic rename capability supports Iceberg\u2019s atomic commit requirements, providing strong consistency for data management without external locking services. Ozone's ability to handle high object counts and its strong consistency model (via Ratis) make it a suitable, reliable backend for Iceberg's transactional, snapshot-based structure."}),"\n",(0,a.jsx)(n.h2,{id:"key-integration-details",children:"Key Integration Details"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Storage and Metadata Management:"})," Iceberg stores data files and metadata files (manifests, snapshots) directly on Ozone."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Atomic Operations:"})," Ozone supports necessary atomic operations for Iceberg\u2019s commit process, ensuring data consistency during concurrent writes."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance:"})," The combination allows for petabyte-scale analytics and fast query planning, overcoming the scalability bottlenecks of traditional HDFS Namenodes."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Compatibility:"})," Iceberg interacts with Ozone using S3-compatible APIs or Hadoop FileSystem interfaces, allowing for seamless integration."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"quickstart",children:"Quickstart"}),"\n",(0,a.jsx)(n.p,{children:"This tutorial shows how to get started with Apache Iceberg to Apache Ozone using the S3 Gateway, with Docker Compose."}),"\n",(0,a.jsx)(n.h3,{id:"quickstart-environment",children:"Quickstart environment"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Unsecure Ozone and Iceberg clusters."}),"\n",(0,a.jsxs)(n.li,{children:["Ozone S3G enables virtual-host style addressing with a subdomain ",(0,a.jsx)(n.code,{children:"s3.ozone"}),".","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["The subdomain and the subdomain with the bucket name ",(0,a.jsx)(n.code,{children:"warehouse.s3.ozone"})," are mapped to the S3 Gateway."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:"Iceberg accesses Ozone via S3 Gateway."}),"\n"]}),"\n",(0,a.jsxs)(n.h3,{id:"step-1--create-docker-composeyaml-for-ozone-services",children:["Step 1 \u2014 Create ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"})," for Ozone services"]}),"\n",(0,a.jsxs)(n.p,{children:["Create a ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"})," file with the following content to"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Spin up a single Datanode Ozone cluster"}),"\n",(0,a.jsxs)(n.li,{children:["Start the S3 Gateway with the required configurations for Iceberg","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Wait for OM to be ready before starting"}),"\n",(0,a.jsxs)(n.li,{children:["Create the bucket ",(0,a.jsx)(n.code,{children:"warehouse"})," on startup"]}),"\n",(0,a.jsx)(n.li,{children:"Mark the S3 Gateway as healthy only after the bucket is created because this is a pre-requisite for Iceberg containers."}),"\n",(0,a.jsx)(n.li,{children:"Define and map the bucket subdomain to the S3 Gateway."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# "License"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nx-image:\n  &image\n  image: ${OZONE_IMAGE:-apache/ozone}:${OZONE_IMAGE_VERSION:-2.1.0}${OZONE_IMAGE_FLAVOR:-}\n\nx-common-config:\n  &common-config\n  OZONE-SITE.XML_hdds.datanode.dir: "/data/hdds"\n  OZONE-SITE.XML_ozone.metadata.dirs: "/data/metadata"\n  OZONE-SITE.XML_ozone.om.address: "om"\n  OZONE-SITE.XML_ozone.om.http-address: "om:9874"\n  OZONE-SITE.XML_ozone.recon.address: "recon:9891"\n  OZONE-SITE.XML_ozone.recon.db.dir: "/data/metadata/recon"\n  OZONE-SITE.XML_ozone.replication: "1"\n  OZONE-SITE.XML_ozone.scm.block.client.address: "scm"\n  OZONE-SITE.XML_ozone.scm.client.address: "scm"\n  OZONE-SITE.XML_ozone.scm.datanode.id.dir: "/data/metadata"\n  OZONE-SITE.XML_ozone.scm.names: "scm"\n  no_proxy: "om,recon,scm,s3g,localhost,127.0.0.1"\n  OZONE-SITE.XML_hdds.scm.safemode.min.datanode: "1"\n  OZONE-SITE.XML_hdds.scm.safemode.healthy.pipeline.pct: "0"\n  OZONE-SITE.XML_ozone.s3g.domain.name: "s3.ozone"\n\nversion: "3"\nservices:\n  datanode:\n    <<: *image\n    ports:\n      - 9864\n    command: ["ozone","datanode"]\n    environment:\n      <<: *common-config\n    networks:\n      iceberg_net:\n  om:\n    <<: *image\n    ports:\n      - 9874:9874\n    environment:\n      <<: *common-config\n      CORE-SITE.XML_hadoop.proxyuser.hadoop.hosts: "*"\n      CORE-SITE.XML_hadoop.proxyuser.hadoop.groups: "*"\n      ENSURE_OM_INITIALIZED: /data/metadata/om/current/VERSION\n      WAITFOR: scm:9876\n    command: ["ozone","om"]\n    networks:\n      iceberg_net:\n  scm:\n    <<: *image\n    ports:\n      - 9876:9876\n    environment:\n      <<: *common-config\n      ENSURE_SCM_INITIALIZED: /data/metadata/scm/current/VERSION\n    command: ["ozone","scm"]\n    networks:\n      iceberg_net:\n  recon:\n    <<: *image\n    ports:\n      - 9888:9888\n    environment:\n      <<: *common-config\n    command: ["ozone","recon"]\n    networks:\n      iceberg_net:\n  s3g:\n    <<: *image\n    ports:\n      - 9878:9878\n    environment:\n      <<: *common-config\n      WAITFOR: om:9874\n    command:\n      - sh\n      - -c\n      - |\n        set -e\n        ozone s3g &\n        s3g_pid=$$!\n        until ozone sh volume list >/dev/null 2>&1; do echo \'...waiting...\' && sleep 1; done;\n        ozone sh bucket delete /s3v/warehouse || true\n        ozone sh bucket create /s3v/warehouse\n        wait "$$s3g_pid"\n    healthcheck:\n      test: [ "CMD", "ozone", "sh", "bucket", "info", "/s3v/warehouse" ]\n      interval: 5s\n      timeout: 3s\n      retries: 10\n      start_period: 30s\n    networks:\n      iceberg_net:\n        aliases:\n          - s3.ozone\n          - warehouse.s3.ozone\n'})}),"\n",(0,a.jsxs)(n.h3,{id:"step-2--create-iceberg-sparkyml-for-iceberg-services",children:["Step 2 \u2014 Create ",(0,a.jsx)(n.code,{children:"iceberg-spark.yml"})," for Iceberg services"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"services:\n  spark-iceberg:\n    image: tabulario/spark-iceberg\n    container_name: spark-iceberg\n    build: spark/\n    networks:\n      iceberg_net:\n    depends_on:\n      rest:\n        condition: service_started\n      s3g:\n        condition: service_healthy\n    volumes:\n      - ./warehouse:/home/iceberg/warehouse\n    environment:\n      - AWS_ACCESS_KEY_ID=admin\n      - AWS_SECRET_ACCESS_KEY=password\n      - AWS_REGION=us-east-1\n    ports:\n      - 8888:8888\n      - 8080:8080\n      - 10000:10000\n      - 10001:10001\n  rest:\n    image: apache/iceberg-rest-fixture\n    container_name: iceberg-rest\n    networks:\n      iceberg_net:\n    ports:\n      - 8181:8181\n    environment:\n      - AWS_ACCESS_KEY_ID=admin\n      - AWS_SECRET_ACCESS_KEY=password\n      - AWS_REGION=us-east-1\n      - CATALOG_WAREHOUSE=s3://warehouse/\n      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO\n      - CATALOG_S3_ENDPOINT=http://s3.ozone:9878\n\nnetworks:\n  iceberg_net:\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-3--start-iceberg-and-ozone-together",children:"Step 3 \u2014 Start Iceberg and Ozone together"}),"\n",(0,a.jsxs)(n.p,{children:["With both ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"})," (for Ozone) and ",(0,a.jsx)(n.code,{children:"docker-compose-flink.yml"})," (for Flink) in the same directory,\nyou can start both services together, sharing the same network, using:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export COMPOSE_FILE=docker-compose.yaml:iceberg-spark.yml\ndocker compose up -d\n"})}),"\n",(0,a.jsx)(n.p,{children:"Verify containers are running:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker ps\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-4--start-a-spark-sql-client",children:"Step 4 \u2014 Start a Spark SQL client"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker exec -it spark-iceberg spark-sql\n"})}),"\n",(0,a.jsx)(n.p,{children:"You should now be in:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"spark-sql ()>\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-5--create-and-query-a-table-backed-by-ozone-s3",children:"Step 5 \u2014 Create and Query a table backed by Ozone S3"}),"\n",(0,a.jsx)(n.p,{children:"Create an Iceberg table stored in Ozone S3:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"    CREATE NAMESPACE IF NOT EXISTS demo.nyc;\n    CREATE TABLE demo.nyc.taxis\n    (\n      vendor_id bigint,\n      trip_id bigint,\n      trip_distance float,\n      fare_amount double,\n      store_and_fwd_flag string\n    )\n    PARTITIONED BY (vendor_id);\n"})}),"\n",(0,a.jsx)(n.p,{children:"Insert data into the table:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"    INSERT INTO demo.nyc.taxis\n    VALUES (1, 1000371, 1.8, 15.32, 'N'), (2, 1000372, 2.5, 22.15, 'N'), (2, 1000373, 0.9, 9.01, 'N'), (1, 1000374, 8.4, 42.13, 'Y');\n"})}),"\n",(0,a.jsx)(n.p,{children:"Query the table:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"    SELECT * FROM demo.nyc.taxis;\n"})}),"\n",(0,a.jsx)(n.p,{children:"Verify data files are stored in Ozone S3:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker compose exec -it s3g ozone fs -ls -R ofs://om/s3v/warehouse\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Spark UI is available at ",(0,a.jsx)(n.code,{children:"http://localhost:8080"}),". You can monitor the Spark jobs here."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},62392:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>i});var t=s(30758);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);