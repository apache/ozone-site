"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[50291],{62392:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>c});var o=s(30758);const t={},a=o.createContext(t);function i(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),o.createElement(a.Provider,{value:n},e.children)}},66060:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>r,contentTitle:()=>c,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"user-guide/client-interfaces/s3a","title":"s3a and Ozone","description":"Ozone exposes an S3-compatible REST interface via the S3 Gateway. Hadoop\'s S3A filesystem (s3a://) is a cloud connector that translates the AWS S3 API into a Hadoop-compatible file system interface. Hadoop-style data analytics tools such as Hive, Impala, and Spark can access Ozone\'s S3 interface using the Hadoop S3A connector, so you can use Ozone buckets from existing Hadoop ecosystem tools without application changes.","source":"@site/versioned_docs/version-2.1.0/04-user-guide/01-client-interfaces/04-s3a.md","sourceDirName":"04-user-guide/01-client-interfaces","slug":"/user-guide/client-interfaces/s3a","permalink":"/docs/user-guide/client-interfaces/s3a","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/master/versioned_docs/version-2.1.0/04-user-guide/01-client-interfaces/04-s3a.md","tags":[],"version":"2.1.0","sidebarPosition":4,"frontMatter":{"sidebar_label":"s3a"},"sidebar":"defaultSidebar","previous":{"title":"Securing S3","permalink":"/docs/user-guide/client-interfaces/s3/securing-s3"},"next":{"title":"HttpFS Gateway","permalink":"/docs/user-guide/client-interfaces/httpfs"}}');var t=s(86070),a=s(62392);const i={sidebar_label:"s3a"},c="s3a and Ozone",r={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Configuring S3A for Ozone",id:"configuring-s3a-for-ozone",level:2},{value:"Enable the S3A client",id:"enable-the-s3a-client",level:3},{value:"core-site.xml: point S3A to Ozone",id:"core-sitexml-point-s3a-to-ozone",level:3},{value:"Recommended settings for Ozone",id:"recommended-settings-for-ozone",level:3},{value:"Credentials",id:"credentials",level:3},{value:"Example: using <code>hadoop fs</code> with Ozone via S3A",id:"example-using-hadoop-fs-with-ozone-via-s3a",level:2},{value:"List objects in an Ozone S3 bucket",id:"list-objects-in-an-ozone-s3-bucket",level:3},{value:"Upload a local file to Ozone using S3A",id:"upload-a-local-file-to-ozone-using-s3a",level:3},{value:"Download from Ozone to local or HDFS",id:"download-from-ozone-to-local-or-hdfs",level:3},{value:"Quick test with inline configuration",id:"quick-test-with-inline-configuration",level:3},{value:"Example: using distcp between HDFS and Ozone",id:"example-using-distcp-between-hdfs-and-ozone",level:2},{value:"Relation to Ozone S3 documentation",id:"relation-to-ozone-s3-documentation",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"s3a-and-ozone",children:"s3a and Ozone"})}),"\n",(0,t.jsxs)(n.p,{children:["Ozone exposes an ",(0,t.jsx)(n.strong,{children:"S3-compatible REST interface"})," via the S3 Gateway. Hadoop's ",(0,t.jsx)(n.strong,{children:"S3A"})," filesystem (",(0,t.jsx)(n.code,{children:"s3a://"}),") is a cloud connector that translates the AWS S3 API into a Hadoop-compatible file system interface. Hadoop-style data analytics tools such as Hive, Impala, and Spark can access Ozone's S3 interface using the Hadoop S3A connector, so you can use Ozone buckets from existing Hadoop ecosystem tools without application changes."]}),"\n",(0,t.jsxs)(n.p,{children:["This page explains how to configure the Hadoop S3A client to use Ozone's S3 Gateway (s3g) and provides sample commands to access Ozone s3g using s3a. For details about the Ozone S3 Gateway itself (supported REST APIs, URL schemes, security), see the ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/s3-api",children:"S3 Protocol"})," page. For more information about S3A, see the ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html",children:"official Hadoop S3A documentation"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["A running Ozone cluster with the ",(0,t.jsx)(n.strong,{children:"S3 Gateway"})," enabled. You can start a Docker-based cluster (including S3 Gateway) as described in the ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/s3-api",children:"S3 Protocol"})," documentation."]}),"\n",(0,t.jsxs)(n.li,{children:["Ozone S3 endpoint (for example ",(0,t.jsx)(n.code,{children:"http://localhost:9878"})," or a load balancer DNS name)."]}),"\n",(0,t.jsxs)(n.li,{children:["Hadoop distribution with the ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"hadoop-aws"})})," module available. See the official Hadoop S3A documentation:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html",children:"Hadoop-AWS: S3A client overview"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/connecting.html",children:"Connecting via S3A"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"configuring-s3a-for-ozone",children:"Configuring S3A for Ozone"}),"\n",(0,t.jsx)(n.h3,{id:"enable-the-s3a-client",children:"Enable the S3A client"}),"\n",(0,t.jsxs)(n.p,{children:["Ensure the ",(0,t.jsx)(n.code,{children:"hadoop-aws"})," module is on the client classpath. In a typical Hadoop installation:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Set ",(0,t.jsx)(n.code,{children:"HADOOP_OPTIONAL_TOOLS"})," in ",(0,t.jsx)(n.code,{children:"hadoop-env.sh"})," to include ",(0,t.jsx)(n.code,{children:"hadoop-aws"}),", ",(0,t.jsx)(n.strong,{children:"or"})]}),"\n",(0,t.jsxs)(n.li,{children:["Add a dependency on ",(0,t.jsx)(n.code,{children:"org.apache.hadoop:hadoop-aws"})," with the same version as ",(0,t.jsx)(n.code,{children:"hadoop-common"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["See the ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Getting_Started",children:"Hadoop S3A Getting Started"})," section for details."]}),"\n",(0,t.jsx)(n.h3,{id:"core-sitexml-point-s3a-to-ozone",children:"core-site.xml: point S3A to Ozone"}),"\n",(0,t.jsxs)(n.p,{children:["Add the following properties to the Hadoop configuration (for example ",(0,t.jsx)(n.code,{children:"core-site.xml"}),") so that ",(0,t.jsx)(n.code,{children:"s3a://"})," URIs use the Ozone S3 Gateway instead of AWS S3:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:"<property>\n  <name>fs.s3a.endpoint</name>\n  <value>http://ozone-s3g-host:9878</value>\n  <description>\n    Ozone S3 Gateway endpoint. Replace with your s3g hostname or load balancer.\n  </description>\n</property>\n\n<property>\n  <name>fs.s3a.endpoint.region</name>\n  <value>us-east-1</value>\n  <description>\n    Logical region name required by the S3A client. Ozone does not enforce regions,\n    but this must be a valid-looking value.\n  </description>\n</property>\n\n<property>\n  <name>fs.s3a.path.style.access</name>\n  <value>true</value>\n  <description>\n    Ozone S3 Gateway defaults to path-style URLs (http://host:9878/bucket),\n    so S3A should use path-style access.\n  </description>\n</property>\n"})}),"\n",(0,t.jsxs)(n.p,{children:["These properties follow the official S3A connection settings in ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/connecting.html#Connection_Settings",children:"Connecting to an S3 store"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"recommended-settings-for-ozone",children:"Recommended settings for Ozone"}),"\n",(0,t.jsx)(n.p,{children:"Ozone S3 Gateway adds ETag support for S3 Multipart Upload (MPU). Object versioning and some other S3 behaviors may still differ from AWS S3. To avoid compatibility issues with older clients or when not using MPU, you can set these options when using S3A with Ozone:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:"<property>\n  <name>fs.s3a.bucket.probe</name>\n  <value>0</value>\n  <description>\n    Disable the bucket existence probe at startup. This is the default in recent Hadoop\n    versions and is recommended for third-party S3-compatible stores such as Ozone.\n  </description>\n</property>\n\n<property>\n  <name>fs.s3a.change.detection.mode</name>\n  <value>none</value>\n  <description>Disable change detection; not applicable to Ozone S3.</description>\n</property>\n"})}),"\n",(0,t.jsx)(n.h3,{id:"credentials",children:"Credentials"}),"\n",(0,t.jsx)(n.p,{children:"Ozone uses the same AWS-style access key and secret key model for the S3 Gateway."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["If ",(0,t.jsx)(n.strong,{children:"security is disabled"}),", any ",(0,t.jsx)(n.code,{children:"AWS_ACCESS_KEY_ID"})," / ",(0,t.jsx)(n.code,{children:"AWS_SECRET_ACCESS_KEY"})," pair can be used."]}),"\n",(0,t.jsxs)(n.li,{children:["If ",(0,t.jsx)(n.strong,{children:"security is enabled"}),", obtain a key and secret via ",(0,t.jsx)(n.code,{children:"ozone s3 getsecret"})," (Kerberos authentication is required). See the ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/s3-api#security",children:"S3 Protocol \u2014 Security"})," and ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/securing-s3",children:"Securing S3"})," sections for details."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Configure S3A credentials in ",(0,t.jsx)(n.code,{children:"core-site.xml"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:"<property>\n  <name>fs.s3a.access.key</name>\n  <value>your-access-key</value>\n</property>\n\n<property>\n  <name>fs.s3a.secret.key</name>\n  <value>your-secret-key</value>\n</property>\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, use environment variables as documented in ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Authenticating_via_the_AWS_Environment_Variables",children:"Authenticating via AWS environment variables"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'export AWS_ACCESS_KEY_ID="your-access-key"\nexport AWS_SECRET_ACCESS_KEY="your-secret-key"\n'})}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["For generating and revoking Ozone S3 secrets, see the ",(0,t.jsx)(n.strong,{children:"Security"})," section of the ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/s3-api#security",children:"S3 Protocol"})," page."]})}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsxs)(n.p,{children:["If the Ozone S3 Gateway is exposed over ",(0,t.jsx)(n.strong,{children:"HTTPS"}),", the JVM must trust the gateway's TLS certificate. The Hadoop AWS client (",(0,t.jsx)(n.code,{children:"hadoop-aws"}),") uses the default Java truststore; if the gateway uses a custom or internal CA, add that CA to ",(0,t.jsx)(n.code,{children:"JAVA_HOME/lib/security/jssecacerts"})," or configure the JVM truststore accordingly. Otherwise S3A connections to the HTTPS endpoint may fail with certificate errors."]})}),"\n",(0,t.jsxs)(n.h2,{id:"example-using-hadoop-fs-with-ozone-via-s3a",children:["Example: using ",(0,t.jsx)(n.code,{children:"hadoop fs"})," with Ozone via S3A"]}),"\n",(0,t.jsx)(n.p,{children:"The examples below assume:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Ozone S3 Gateway is reachable at ",(0,t.jsx)(n.code,{children:"http://localhost:9878"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"core-site.xml"})," is configured as above"]}),"\n",(0,t.jsxs)(n.li,{children:["An S3 bucket (for example ",(0,t.jsx)(n.code,{children:"bucket1"}),") already exists (you can create it with ",(0,t.jsx)(n.code,{children:"aws s3api --endpoint http://localhost:9878 create-bucket --bucket bucket1"}),")"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["S3A URLs use the form ",(0,t.jsx)(n.code,{children:"s3a://<bucket>/<path>"}),". The bucket corresponds to an Ozone bucket under the ",(0,t.jsx)(n.code,{children:"/s3v"})," volume or a bucket link."]}),"\n",(0,t.jsx)(n.h3,{id:"list-objects-in-an-ozone-s3-bucket",children:"List objects in an Ozone S3 bucket"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"hadoop fs -ls s3a://bucket1/\n"})}),"\n",(0,t.jsx)(n.h3,{id:"upload-a-local-file-to-ozone-using-s3a",children:"Upload a local file to Ozone using S3A"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"hadoop fs -put /data/local-file.txt s3a://bucket1/path/local-file.txt\n"})}),"\n",(0,t.jsx)(n.h3,{id:"download-from-ozone-to-local-or-hdfs",children:"Download from Ozone to local or HDFS"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# To local filesystem\nhadoop fs -copyToLocal s3a://bucket1/path/file.txt /tmp/from-ozone.txt\n\n# Copy to HDFS\nhadoop fs -cp s3a://bucket1/path/file.txt hdfs:///user/test/from-ozone.txt\n"})}),"\n",(0,t.jsx)(n.h3,{id:"quick-test-with-inline-configuration",children:"Quick test with inline configuration"}),"\n",(0,t.jsxs)(n.p,{children:["If you cannot modify cluster-wide ",(0,t.jsx)(n.code,{children:"core-site.xml"}),", you can pass S3A options on the command line. Replace the endpoint, bucket, and credentials with your values:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"hadoop fs \\\n  -D fs.s3a.endpoint=http://localhost:9878 \\\n  -D fs.s3a.endpoint.region=us-east-1 \\\n  -D fs.s3a.path.style.access=true \\\n  -D fs.s3a.bucket.probe=0 \\\n  -D fs.s3a.change.detection.mode=none \\\n  -D fs.s3a.access.key=your-access-key \\\n  -D fs.s3a.secret.key=your-secret-key \\\n  -ls s3a://bucket1/\n"})}),"\n",(0,t.jsx)(n.h2,{id:"example-using-distcp-between-hdfs-and-ozone",children:"Example: using distcp between HDFS and Ozone"}),"\n",(0,t.jsxs)(n.p,{children:["You can use S3A as a source or destination for ",(0,t.jsx)(n.code,{children:"distcp"})," to move data between HDFS and Ozone. Use the same S3A configuration as above."]}),"\n",(0,t.jsx)(n.p,{children:"Copy from HDFS to Ozone:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"hadoop distcp hdfs:///data/source/dir s3a://bucket1/backup/dir\n"})}),"\n",(0,t.jsx)(n.p,{children:"Copy from Ozone to HDFS:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"hadoop distcp s3a://bucket1/backup/dir hdfs:///data/restore/dir\n"})}),"\n",(0,t.jsx)(n.h2,{id:"relation-to-ozone-s3-documentation",children:"Relation to Ozone S3 documentation"}),"\n",(0,t.jsxs)(n.p,{children:["This page describes using Ozone from the ",(0,t.jsx)(n.strong,{children:"Hadoop FileSystem"})," perspective (S3A client). For REST API details, supported S3 operations, bucket linking, and S3 security, see the ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/s3-api",children:"S3 Protocol"})," and ",(0,t.jsx)(n.a,{href:"/docs/user-guide/client-interfaces/s3/securing-s3",children:"Securing S3"})," pages."]}),"\n",(0,t.jsxs)(n.p,{children:["For advanced S3A options (performance tuning, encryption, retries), refer to the official ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html",children:"Hadoop S3A documentation"})," and its sub-pages such as ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/performance.html",children:"Performance"})," and ",(0,t.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/encryption.html",children:"Encryption"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);