"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[11670],{50064:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"user-guide/integrations/flink","title":"Apache Flink","description":"Apache Flink is a powerful, open-source distributed processing framework designed for stateful computations over both bounded and unbounded data streams at any scale. It enables high-throughput, low-latency, and fault-tolerant processing while offering elastic scaling capabilities to handle millions of events per second across thousands of cores.","source":"@site/versioned_docs/version-2.1.0/04-user-guide/03-integrations/09-flink.md","sourceDirName":"04-user-guide/03-integrations","slug":"/user-guide/integrations/flink","permalink":"/docs/user-guide/integrations/flink","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ozone-site/tree/master/versioned_docs/version-2.1.0/04-user-guide/03-integrations/09-flink.md","tags":[],"version":"2.1.0","sidebarPosition":9,"frontMatter":{"sidebar_label":"Flink"},"sidebar":"defaultSidebar","previous":{"title":"DistCp","permalink":"/docs/user-guide/integrations/hadoop-distcp"},"next":{"title":"HBase","permalink":"/docs/user-guide/integrations/hbase"}}');var a=s(86070),t=s(62392);const i={sidebar_label:"Flink"},r="Apache Flink",c={},l=[{value:"Quickstart",id:"quickstart",level:2},{value:"Quickstart environment",id:"quickstart-environment",level:3},{value:"Step 1 \u2014 Download Ozone&#39;s <code>docker-compose.yaml</code>",id:"step-1--download-ozones-docker-composeyaml",level:3},{value:"Step 2 \u2014 Create <code>docker-compose-flink.yml</code> for Flink",id:"step-2--create-docker-compose-flinkyml-for-flink",level:3},{value:"Step 3 \u2014 Start Flink and Ozone together",id:"step-3--start-flink-and-ozone-together",level:3},{value:"Step 4 \u2014 Create an Ozone bucket",id:"step-4--create-an-ozone-bucket",level:3},{value:"Step 5 \u2014 Start Flink SQL client",id:"step-5--start-flink-sql-client",level:3},{value:"Step 6 \u2014 Create and Query a table backed by Ozone S3",id:"step-6--create-and-query-a-table-backed-by-ozone-s3",level:3},{value:"Step 7 \u2014 Check Flink job status in the Web UI",id:"step-7--check-flink-job-status-in-the-web-ui",level:3},{value:"Key takeaways (important)",id:"key-takeaways-important",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"apache-flink",children:"Apache Flink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://flink.apache.org/",children:"Apache Flink"})," is a powerful, open-source distributed processing framework designed for stateful computations over both bounded and unbounded data streams at any scale. It enables high-throughput, low-latency, and fault-tolerant processing while offering elastic scaling capabilities to handle millions of events per second across thousands of cores."]}),"\n",(0,a.jsx)(n.p,{children:"Apache Flink can use Apache Ozone for reading and writing data, and for storing essential operational components like application state checkpoints and savepoints."}),"\n",(0,a.jsx)(n.h2,{id:"quickstart",children:"Quickstart"}),"\n",(0,a.jsx)(n.p,{children:"This tutorial shows how to get started with connecting Apache Flink to Apache Ozone using the S3 Gateway, with Docker Compose."}),"\n",(0,a.jsx)(n.h3,{id:"quickstart-environment",children:"Quickstart environment"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Unsecure Ozone and Flink clusters."}),"\n",(0,a.jsxs)(n.li,{children:["Ozone S3G enables path style access. To enable virtual-host style addressing see ",(0,a.jsx)(n.a,{href:"../client-interfaces/s3/s3-api#url-schema",children:"here"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"Flink accesses Ozone via S3 Gateway."}),"\n"]}),"\n",(0,a.jsxs)(n.h3,{id:"step-1--download-ozones-docker-composeyaml",children:["Step 1 \u2014 Download Ozone's ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"})]}),"\n",(0,a.jsxs)(n.p,{children:["First, obtain Ozone's sample Docker Compose configuration and save it as ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"curl -O https://raw.githubusercontent.com/apache/ozone-docker/refs/heads/latest/docker-compose.yaml\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Edit the ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"}),":"]}),"\n",(0,a.jsxs)(n.p,{children:["Append the last 2 SCM safemode configurations to the ",(0,a.jsx)(n.code,{children:"x-common-config:"})," section to enable starting with a single Datanode."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'x-common-config:\n   &common-config\n   ...\n   no_proxy: "om,recon,scm,s3g,localhost,127.0.0.1"\n   OZONE-SITE.XML_hdds.scm.safemode.min.datanode: "1"\n   OZONE-SITE.XML_hdds.scm.safemode.healthy.pipeline.pct: "0" \n'})}),"\n",(0,a.jsxs)(n.p,{children:["Refer to the ",(0,a.jsx)(n.a,{href:"../../quick-start/installation/docker",children:"Docker quick start page"})," for details."]}),"\n",(0,a.jsxs)(n.h3,{id:"step-2--create-docker-compose-flinkyml-for-flink",children:["Step 2 \u2014 Create ",(0,a.jsx)(n.code,{children:"docker-compose-flink.yml"})," for Flink"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'services:\n  jobmanager:\n    image: flink:scala_2.12-java17\n    command: >\n      bash -c "mkdir -p /opt/flink/plugins/s3-fs-hadoop &&\n      cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&\n      /docker-entrypoint.sh jobmanager"\n    ports:\n      - "8081:8081"\n    environment:\n      AWS_ACCESS_KEY_ID: ozone\n      AWS_SECRET_ACCESS_KEY: ozone\n      FLINK_PROPERTIES: |\n        jobmanager.rpc.address: jobmanager\n        fs.s3a.endpoint: http://s3g:9878\n        fs.s3a.path.style.access: true\n        fs.s3a.connection.ssl.enabled: false\n        fs.s3a.access.key: ozone\n        fs.s3a.secret.key: ozone\n\n  taskmanager:\n    image: flink:scala_2.12-java17\n    command: >\n      bash -c "mkdir -p /opt/flink/plugins/s3-fs-hadoop &&\n      cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&\n      /docker-entrypoint.sh taskmanager"\n    depends_on:\n      - jobmanager\n    environment:\n      AWS_ACCESS_KEY_ID: ozone\n      AWS_SECRET_ACCESS_KEY: ozone\n      FLINK_PROPERTIES: |\n        jobmanager.rpc.address: jobmanager\n        taskmanager.numberOfTaskSlots: 4\n        fs.s3a.endpoint: http://s3g:9878\n        fs.s3a.path.style.access: true\n        fs.s3a.connection.ssl.enabled: false\n        fs.s3a.access.key: ozone\n        fs.s3a.secret.key: ozone\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-3--start-flink-and-ozone-together",children:"Step 3 \u2014 Start Flink and Ozone together"}),"\n",(0,a.jsxs)(n.p,{children:["With both ",(0,a.jsx)(n.code,{children:"docker-compose.yaml"})," (for Ozone) and ",(0,a.jsx)(n.code,{children:"docker-compose-flink.yml"})," (for Flink) in the same directory,\nyou can start both services together, sharing the same network, using:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export COMPOSE_FILE=docker-compose.yaml:docker-compose-flink.yml\ndocker compose up -d\n"})}),"\n",(0,a.jsx)(n.p,{children:"Verify containers are running:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker ps\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-4--create-an-ozone-bucket",children:"Step 4 \u2014 Create an Ozone bucket"}),"\n",(0,a.jsxs)(n.p,{children:["You need to connect to Ozone (for example, ",(0,a.jsx)(n.code,{children:"s3g"}),") to create a OBS bucket:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker compose exec -it s3g ozone sh bucket create s3v/bucket1 -l obs\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-5--start-flink-sql-client",children:"Step 5 \u2014 Start Flink SQL client"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker compose exec -it jobmanager ./bin/sql-client.sh\n"})}),"\n",(0,a.jsx)(n.p,{children:"You should now be in:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"Flink SQL>\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-6--create-and-query-a-table-backed-by-ozone-s3",children:"Step 6 \u2014 Create and Query a table backed by Ozone S3"}),"\n",(0,a.jsx)(n.p,{children:"Important: Must use BATCH mode otherwise multi-part upload fails."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"SET 'execution.runtime-mode' = 'BATCH';\n\nCREATE TABLE ozone_sink (\n  id STRING,\n  ts TIMESTAMP(3)\n) WITH (\n  'connector' = 'filesystem',\n  'path' = 's3a://bucket1/ozone_sink/',\n  'format' = 'csv'\n);\n"})}),"\n",(0,a.jsx)(n.p,{children:"Insert data:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"INSERT INTO ozone_sink VALUES ('hello', CURRENT_TIMESTAMP);\n"})}),"\n",(0,a.jsx)(n.p,{children:"Query it:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM ozone_sink;\n"})}),"\n",(0,a.jsx)(n.p,{children:"If this works, Flink is successfully reading/writing Ozone via S3."}),"\n",(0,a.jsx)(n.h3,{id:"step-7--check-flink-job-status-in-the-web-ui",children:"Step 7 \u2014 Check Flink job status in the Web UI"}),"\n",(0,a.jsx)(n.p,{children:"Open your browser:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"http://localhost:8081/\n"})}),"\n",(0,a.jsx)(n.p,{children:"Here you can:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"See running and completed jobs"}),"\n",(0,a.jsx)(n.li,{children:"Inspect TaskManagers"}),"\n",(0,a.jsx)(n.li,{children:"Debug failures visually"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"This is the first place to look if something goes wrong."}),"\n",(0,a.jsx)(n.h2,{id:"key-takeaways-important",children:"Key takeaways (important)"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Flink Docker images do not ship with S3 enabled"}),"\n",(0,a.jsx)(n.li,{children:"The S3 plugin must exist in both JM and TM"}),"\n",(0,a.jsxs)(n.li,{children:["Flink and Ozone should be started using a combined Docker Compose file (",(0,a.jsx)(n.code,{children:"COMPOSE_FILE"}),") to ensure they share the same network."]}),"\n",(0,a.jsxs)(n.li,{children:["Always use ",(0,a.jsx)(n.code,{children:"s3a://"})," with ",(0,a.jsx)(n.code,{children:"flink-s3-fs-hadoop"})]}),"\n",(0,a.jsxs)(n.li,{children:["Check ",(0,a.jsx)(n.code,{children:"http://localhost:8081/"})," to confirm jobs are running"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Batch mode is required"})," for Flink SQL to avoid multipart upload failures to Ozone. Use ",(0,a.jsx)(n.code,{children:"SET 'execution.runtime-mode' = 'BATCH';"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},62392:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>r});var o=s(30758);const a={},t=o.createContext(a);function i(e){const n=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);